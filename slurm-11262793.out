The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) 2023.01   2) StdEnv
/scratch/s1889338/all_captions/venv/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
A new version of the following files was downloaded from https://huggingface.co/THUDM/cogvlm-chat-hf:
- configuration_cogvlm.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
A new version of the following files was downloaded from https://huggingface.co/THUDM/cogvlm-chat-hf:
- modeling_cogvlm.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
Python version is above 3.10, patching the collections module.
Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 8/8 [00:00<00:00, 229.10it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:01<00:07,  1.06s/it]Loading checkpoint shards:  25%|██▌       | 2/8 [00:01<00:04,  1.27it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:02<00:03,  1.43it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:03<00:03,  1.19it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:04<00:02,  1.24it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:05<00:02,  1.13s/it]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:07<00:01,  1.41s/it]Loading checkpoint shards: 100%|██████████| 8/8 [00:07<00:00,  1.00s/it]Loading checkpoint shards: 100%|██████████| 8/8 [00:07<00:00,  1.01it/s]
  0%|          | 0/75 [00:00<?, ?w/s]model.embed_tokens.weight:   0%|          | 0/75 [00:00<?, ?w/s, dev=0]model.embed_tokens.weight:   1%|▏         | 1/75 [00:00<01:12,  1.02w/s, dev=0]model.layers.0.input_layernorm.weight:   1%|▏         | 1/75 [00:00<01:12,  1.02w/s, dev=0]model.layers.0.mlp.language_mlp.down_proj.weight:   3%|▎         | 2/75 [00:00<00:35,  2.03w/s, dev=0]model.layers.0.mlp.language_mlp.gate_proj.weight:   4%|▍         | 3/75 [00:01<00:24,  2.93w/s, dev=0]model.layers.0.mlp.language_mlp.up_proj.weight:   5%|▌         | 4/75 [00:01<00:18,  3.76w/s, dev=0]  model.layers.0.mlp.language_mlp.up_proj.weight:   7%|▋         | 5/75 [00:01<00:15,  4.54w/s, dev=0]model.layers.0.mlp.vision_mlp.down_proj.weight:   7%|▋         | 5/75 [00:01<00:15,  4.54w/s, dev=0]model.layers.0.mlp.vision_mlp.gate_proj.weight:   8%|▊         | 6/75 [00:01<00:14,  4.86w/s, dev=0]model.layers.0.mlp.vision_mlp.up_proj.weight:   9%|▉         | 7/75 [00:01<00:12,  5.29w/s, dev=0]  model.layers.0.post_attention_layernorm.weight:  11%|█         | 8/75 [00:01<00:11,  5.88w/s, dev=0]model.layers.0.post_attention_layernorm.weight:  12%|█▏        | 9/75 [00:01<00:09,  6.61w/s, dev=0]model.layers.0.self_attn.language_expert_dense.weight:  12%|█▏        | 9/75 [00:01<00:09,  6.61w/s, dev=0]model.layers.0.self_attn.language_expert_query_key_value.weight:  13%|█▎        | 10/75 [00:01<00:08,  7.27w/s, dev=0]model.layers.0.self_attn.rotary_emb.inv_freq:  15%|█▍        | 11/75 [00:01<00:08,  7.62w/s, dev=0]                   model.layers.0.self_attn.vision_expert_dense.weight:  16%|█▌        | 12/75 [00:01<00:07,  8.31w/s, dev=0]model.layers.0.self_attn.vision_expert_dense.weight:  17%|█▋        | 13/75 [00:01<00:07,  8.83w/s, dev=0]model.layers.0.self_attn.vision_expert_query_key_value.weight:  17%|█▋        | 13/75 [00:01<00:07,  8.83w/s, dev=0]model.layers.1.input_layernorm.weight:  19%|█▊        | 14/75 [00:01<00:06,  9.02w/s, dev=0]                        model.layers.1.mlp.language_mlp.down_proj.weight:  20%|██        | 15/75 [00:01<00:06,  9.66w/s, dev=0]model.layers.1.mlp.language_mlp.gate_proj.weight:  21%|██▏       | 16/75 [00:01<00:05,  9.86w/s, dev=0]model.layers.1.mlp.language_mlp.gate_proj.weight:  23%|██▎       | 17/75 [00:01<00:05,  9.99w/s, dev=0]model.layers.1.mlp.language_mlp.up_proj.weight:  23%|██▎       | 17/75 [00:01<00:05,  9.99w/s, dev=0]  model.layers.1.mlp.vision_mlp.down_proj.weight:  24%|██▍       | 18/75 [00:01<00:05, 10.12w/s, dev=0]model.layers.1.mlp.vision_mlp.gate_proj.weight:  25%|██▌       | 19/75 [00:01<00:05, 10.15w/s, dev=0]model.layers.1.mlp.vision_mlp.up_proj.weight:  27%|██▋       | 20/75 [00:01<00:05, 10.07w/s, dev=0]  model.layers.1.mlp.vision_mlp.up_proj.weight:  28%|██▊       | 21/75 [00:02<00:05, 10.21w/s, dev=0]model.layers.1.post_attention_layernorm.weight:  28%|██▊       | 21/75 [00:02<00:05, 10.21w/s, dev=0]model.layers.1.self_attn.language_expert_dense.weight:  29%|██▉       | 22/75 [00:02<00:04, 10.69w/s, dev=0]model.layers.1.self_attn.language_expert_query_key_value.weight:  31%|███       | 23/75 [00:02<00:04, 10.96w/s, dev=0]model.layers.1.self_attn.rotary_emb.inv_freq:  32%|███▏      | 24/75 [00:02<00:04, 11.04w/s, dev=0]                   model.layers.1.self_attn.rotary_emb.inv_freq:  33%|███▎      | 25/75 [00:02<00:04, 11.50w/s, dev=0]model.layers.1.self_attn.vision_expert_dense.weight:  33%|███▎      | 25/75 [00:02<00:04, 11.50w/s, dev=0]model.layers.1.self_attn.vision_expert_query_key_value.weight:  35%|███▍      | 26/75 [00:02<00:04, 11.71w/s, dev=0]model.layers.2.input_layernorm.weight:  36%|███▌      | 27/75 [00:02<00:04, 11.32w/s, dev=0]                        model.layers.2.mlp.language_mlp.down_proj.weight:  37%|███▋      | 28/75 [00:02<00:04, 11.74w/s, dev=0]model.layers.2.mlp.language_mlp.down_proj.weight:  39%|███▊      | 29/75 [00:02<00:03, 11.77w/s, dev=0]model.layers.2.mlp.language_mlp.gate_proj.weight:  39%|███▊      | 29/75 [00:02<00:03, 11.77w/s, dev=0]model.layers.2.mlp.language_mlp.up_proj.weight:  40%|████      | 30/75 [00:02<00:03, 11.87w/s, dev=0]  model.layers.2.mlp.vision_mlp.down_proj.weight:  41%|████▏     | 31/75 [00:02<00:03, 11.91w/s, dev=0]model.layers.2.mlp.vision_mlp.gate_proj.weight:  43%|████▎     | 32/75 [00:02<00:03, 11.96w/s, dev=0]model.layers.2.mlp.vision_mlp.gate_proj.weight:  44%|████▍     | 33/75 [00:02<00:03, 12.01w/s, dev=0]model.layers.2.mlp.vision_mlp.up_proj.weight:  44%|████▍     | 33/75 [00:02<00:03, 12.01w/s, dev=0]  model.layers.2.post_attention_layernorm.weight:  45%|████▌     | 34/75 [00:02<00:03, 12.06w/s, dev=0]model.layers.2.self_attn.language_expert_dense.weight:  47%|████▋     | 35/75 [00:02<00:03, 12.41w/s, dev=0]model.layers.2.self_attn.language_expert_query_key_value.weight:  48%|████▊     | 36/75 [00:02<00:03, 12.63w/s, dev=0]model.layers.2.self_attn.language_expert_query_key_value.weight:  49%|████▉     | 37/75 [00:02<00:03, 12.63w/s, dev=0]model.layers.2.self_attn.rotary_emb.inv_freq:  49%|████▉     | 37/75 [00:02<00:03, 12.63w/s, dev=0]                   model.layers.2.self_attn.vision_expert_dense.weight:  51%|█████     | 38/75 [00:02<00:02, 12.97w/s, dev=0]model.layers.2.self_attn.vision_expert_query_key_value.weight:  52%|█████▏    | 39/75 [00:02<00:02, 13.17w/s, dev=0]model.layers.3.input_layernorm.weight:  53%|█████▎    | 40/75 [00:03<00:02, 13.16w/s, dev=0]                        model.layers.3.input_layernorm.weight:  55%|█████▍    | 41/75 [00:03<00:02, 13.48w/s, dev=0]model.layers.3.mlp.language_mlp.down_proj.weight:  55%|█████▍    | 41/75 [00:03<00:02, 13.48w/s, dev=0]model.layers.3.mlp.language_mlp.gate_proj.weight:  56%|█████▌    | 42/75 [00:03<00:02, 13.02w/s, dev=0]model.layers.3.mlp.language_mlp.up_proj.weight:  57%|█████▋    | 43/75 [00:03<00:02, 13.16w/s, dev=0]  model.layers.3.mlp.vision_mlp.down_proj.weight:  59%|█████▊    | 44/75 [00:03<00:02, 13.01w/s, dev=0]model.layers.3.mlp.vision_mlp.down_proj.weight:  60%|██████    | 45/75 [00:03<00:02, 13.14w/s, dev=0]model.layers.3.mlp.vision_mlp.gate_proj.weight:  60%|██████    | 45/75 [00:03<00:02, 13.14w/s, dev=0]model.layers.3.mlp.vision_mlp.up_proj.weight:  61%|██████▏   | 46/75 [00:03<00:02, 12.85w/s, dev=0]  model.layers.3.post_attention_layernorm.weight:  63%|██████▎   | 47/75 [00:03<00:02, 12.99w/s, dev=0]model.layers.3.self_attn.language_expert_dense.weight:  64%|██████▍   | 48/75 [00:03<00:02, 13.27w/s, dev=0]model.layers.3.self_attn.language_expert_dense.weight:  65%|██████▌   | 49/75 [00:03<00:01, 13.49w/s, dev=0]model.layers.3.self_attn.language_expert_query_key_value.weight:  65%|██████▌   | 49/75 [00:03<00:01, 13.49w/s, dev=0]model.layers.3.self_attn.rotary_emb.inv_freq:  67%|██████▋   | 50/75 [00:03<00:01, 13.53w/s, dev=0]                   model.layers.3.self_attn.vision_expert_dense.weight:  68%|██████▊   | 51/75 [00:03<00:01, 13.79w/s, dev=0]model.layers.3.self_attn.vision_expert_query_key_value.weight:  69%|██████▉   | 52/75 [00:03<00:01, 13.95w/s, dev=0]model.layers.3.self_attn.vision_expert_query_key_value.weight:  71%|███████   | 53/75 [00:03<00:01, 13.91w/s, dev=0]model.layers.4.input_layernorm.weight:  71%|███████   | 53/75 [00:03<00:01, 13.91w/s, dev=0]                        model.layers.4.mlp.language_mlp.down_proj.weight:  72%|███████▏  | 54/75 [00:03<00:01, 14.17w/s, dev=0]model.layers.4.mlp.language_mlp.gate_proj.weight:  73%|███████▎  | 55/75 [00:03<00:01, 14.17w/s, dev=0]model.layers.4.mlp.language_mlp.up_proj.weight:  75%|███████▍  | 56/75 [00:04<00:01, 13.96w/s, dev=0]  model.layers.4.mlp.language_mlp.up_proj.weight:  76%|███████▌  | 57/75 [00:04<00:01, 13.91w/s, dev=0]model.layers.4.mlp.vision_mlp.down_proj.weight:  76%|███████▌  | 57/75 [00:04<00:01, 13.91w/s, dev=0]model.layers.4.mlp.vision_mlp.gate_proj.weight:  77%|███████▋  | 58/75 [00:04<00:01, 13.62w/s, dev=0]model.layers.4.mlp.vision_mlp.up_proj.weight:  79%|███████▊  | 59/75 [00:04<00:01, 13.73w/s, dev=0]  model.layers.4.post_attention_layernorm.weight:  80%|████████  | 60/75 [00:04<00:01, 13.52w/s, dev=0]model.layers.4.post_attention_layernorm.weight:  81%|████████▏ | 61/75 [00:04<00:01, 13.74w/s, dev=0]model.layers.4.self_attn.language_expert_dense.weight:  81%|████████▏ | 61/75 [00:04<00:01, 13.74w/s, dev=0]model.layers.4.self_attn.language_expert_query_key_value.weight:  83%|████████▎ | 62/75 [00:04<00:00, 13.92w/s, dev=0]model.layers.4.self_attn.rotary_emb.inv_freq:  84%|████████▍ | 63/75 [00:04<00:00, 13.88w/s, dev=0]                   model.layers.4.self_attn.vision_expert_dense.weight:  85%|████████▌ | 64/75 [00:04<00:00, 14.10w/s, dev=0]model.layers.4.self_attn.vision_expert_dense.weight:  87%|████████▋ | 65/75 [00:04<00:00, 14.25w/s, dev=0]model.layers.4.self_attn.vision_expert_query_key_value.weight:  87%|████████▋ | 65/75 [00:04<00:00, 14.25w/s, dev=0]model.layers.5.mlp.language_mlp.down_proj.weight:  88%|████████▊ | 66/75 [00:04<00:00, 14.07w/s, dev=0]             model.layers.5.mlp.language_mlp.gate_proj.weight:  89%|████████▉ | 67/75 [00:04<00:00, 14.07w/s, dev=0]model.layers.5.mlp.language_mlp.up_proj.weight:  91%|█████████ | 68/75 [00:04<00:00, 13.90w/s, dev=0]  model.layers.5.mlp.language_mlp.up_proj.weight:  92%|█████████▏| 69/75 [00:05<00:00, 13.57w/s, dev=0]model.layers.5.mlp.vision_mlp.gate_proj.weight:  92%|█████████▏| 69/75 [00:05<00:00, 13.57w/s, dev=0]model.layers.5.self_attn.language_expert_dense.weight:  93%|█████████▎| 70/75 [00:05<00:00, 13.66w/s, dev=0]model.layers.5.self_attn.language_expert_query_key_value.weight:  95%|█████████▍| 71/75 [00:05<00:00, 13.80w/s, dev=0]model.layers.5.self_attn.rotary_emb.inv_freq:  96%|█████████▌| 72/75 [00:05<00:00, 13.71w/s, dev=0]                   model.layers.5.self_attn.rotary_emb.inv_freq:  97%|█████████▋| 73/75 [00:05<00:00, 13.90w/s, dev=0]model.layers.5.self_attn.vision_expert_dense.weight:  97%|█████████▋| 73/75 [00:05<00:00, 13.90w/s, dev=0]model.layers.5.self_attn.vision_expert_query_key_value.weight:  99%|█████████▊| 74/75 [00:05<00:00, 14.01w/s, dev=0]                                                                                                                      0%|          | 0/79 [00:00<?, ?w/s]model.layers.5.input_layernorm.weight:   0%|          | 0/79 [00:00<?, ?w/s, dev=0]model.layers.5.mlp.vision_mlp.down_proj.weight:   1%|▏         | 1/79 [00:00<00:00, 530.99w/s, dev=0]model.layers.5.mlp.vision_mlp.down_proj.weight:   3%|▎         | 2/79 [00:00<00:09,  8.18w/s, dev=0] model.layers.5.mlp.vision_mlp.up_proj.weight:   3%|▎         | 2/79 [00:00<00:09,  8.17w/s, dev=0]  model.layers.5.post_attention_layernorm.weight:   4%|▍         | 3/79 [00:00<00:07, 10.59w/s, dev=0]model.layers.6.input_layernorm.weight:   5%|▌         | 4/79 [00:00<00:05, 14.11w/s, dev=0]         model.layers.6.mlp.language_mlp.down_proj.weight:   6%|▋         | 5/79 [00:00<00:04, 17.62w/s, dev=0]model.layers.6.mlp.language_mlp.gate_proj.weight:   8%|▊         | 6/79 [00:00<00:03, 18.71w/s, dev=0]model.layers.6.mlp.language_mlp.gate_proj.weight:   9%|▉         | 7/79 [00:00<00:03, 19.57w/s, dev=0]model.layers.6.mlp.language_mlp.up_proj.weight:   9%|▉         | 7/79 [00:00<00:03, 19.56w/s, dev=0]  model.layers.6.mlp.vision_mlp.down_proj.weight:  10%|█         | 8/79 [00:00<00:03, 20.28w/s, dev=0]model.layers.6.mlp.vision_mlp.gate_proj.weight:  11%|█▏        | 9/79 [00:00<00:03, 20.51w/s, dev=0]model.layers.6.mlp.vision_mlp.up_proj.weight:  13%|█▎        | 10/79 [00:00<00:03, 20.75w/s, dev=0] model.layers.6.post_attention_layernorm.weight:  14%|█▍        | 11/79 [00:00<00:03, 20.79w/s, dev=0]model.layers.6.post_attention_layernorm.weight:  15%|█▌        | 12/79 [00:00<00:02, 22.66w/s, dev=0]model.layers.6.self_attn.language_expert_dense.weight:  15%|█▌        | 12/79 [00:00<00:02, 22.66w/s, dev=0]model.layers.6.self_attn.language_expert_query_key_value.weight:  16%|█▋        | 13/79 [00:00<00:03, 20.85w/s, dev=0]model.layers.6.self_attn.rotary_emb.inv_freq:  18%|█▊        | 14/79 [00:00<00:03, 21.04w/s, dev=0]                   model.layers.6.self_attn.vision_expert_dense.weight:  19%|█▉        | 15/79 [00:00<00:02, 22.53w/s, dev=0]model.layers.6.self_attn.vision_expert_query_key_value.weight:  20%|██        | 16/79 [00:00<00:02, 23.54w/s, dev=0]model.layers.6.self_attn.vision_expert_query_key_value.weight:  22%|██▏       | 17/79 [00:00<00:02, 22.64w/s, dev=0]model.layers.7.input_layernorm.weight:  22%|██▏       | 17/79 [00:00<00:02, 22.63w/s, dev=0]                        model.layers.7.mlp.language_mlp.down_proj.weight:  23%|██▎       | 18/79 [00:00<00:02, 23.95w/s, dev=0]model.layers.7.mlp.language_mlp.gate_proj.weight:  24%|██▍       | 19/79 [00:00<00:02, 24.11w/s, dev=0]model.layers.7.mlp.language_mlp.up_proj.weight:  25%|██▌       | 20/79 [00:01<00:03, 19.18w/s, dev=0]  model.layers.7.mlp.vision_mlp.down_proj.weight:  27%|██▋       | 21/79 [00:01<00:02, 19.42w/s, dev=0]model.layers.7.mlp.vision_mlp.down_proj.weight:  28%|██▊       | 22/79 [00:01<00:02, 19.67w/s, dev=0]model.layers.7.mlp.vision_mlp.gate_proj.weight:  28%|██▊       | 22/79 [00:01<00:02, 19.66w/s, dev=0]model.layers.7.mlp.vision_mlp.up_proj.weight:  29%|██▉       | 23/79 [00:01<00:02, 19.91w/s, dev=0]  model.layers.7.post_attention_layernorm.weight:  30%|███       | 24/79 [00:01<00:02, 20.13w/s, dev=0]model.layers.7.self_attn.language_expert_dense.weight:  32%|███▏      | 25/79 [00:01<00:02, 20.96w/s, dev=0]model.layers.7.self_attn.language_expert_query_key_value.weight:  33%|███▎      | 26/79 [00:01<00:02, 21.55w/s, dev=0]model.layers.7.self_attn.language_expert_query_key_value.weight:  34%|███▍      | 27/79 [00:01<00:02, 21.35w/s, dev=0]model.layers.7.self_attn.rotary_emb.inv_freq:  34%|███▍      | 27/79 [00:01<00:02, 21.35w/s, dev=0]                   model.layers.7.self_attn.vision_expert_dense.weight:  35%|███▌      | 28/79 [00:01<00:02, 22.13w/s, dev=0]model.layers.7.self_attn.vision_expert_query_key_value.weight:  37%|███▋      | 29/79 [00:01<00:02, 22.67w/s, dev=0]model.layers.8.input_layernorm.weight:  38%|███▊      | 30/79 [00:01<00:02, 22.74w/s, dev=0]                        model.layers.8.mlp.language_mlp.down_proj.weight:  39%|███▉      | 31/79 [00:01<00:02, 23.49w/s, dev=0]model.layers.8.mlp.language_mlp.down_proj.weight:  41%|████      | 32/79 [00:01<00:02, 23.15w/s, dev=0]model.layers.8.mlp.language_mlp.gate_proj.weight:  41%|████      | 32/79 [00:01<00:02, 23.14w/s, dev=0]model.layers.8.mlp.language_mlp.up_proj.weight:  42%|████▏     | 33/79 [00:01<00:02, 21.76w/s, dev=0]  model.layers.8.mlp.vision_mlp.down_proj.weight:  43%|████▎     | 34/79 [00:01<00:02, 20.31w/s, dev=0]model.layers.8.mlp.vision_mlp.gate_proj.weight:  44%|████▍     | 35/79 [00:01<00:02, 20.46w/s, dev=0]model.layers.8.mlp.vision_mlp.up_proj.weight:  46%|████▌     | 36/79 [00:01<00:02, 20.59w/s, dev=0]  model.layers.8.mlp.vision_mlp.up_proj.weight:  47%|████▋     | 37/79 [00:01<00:02, 20.72w/s, dev=0]model.layers.8.post_attention_layernorm.weight:  47%|████▋     | 37/79 [00:01<00:02, 20.72w/s, dev=0]model.layers.8.self_attn.language_expert_dense.weight:  48%|████▊     | 38/79 [00:01<00:01, 21.27w/s, dev=0]model.layers.8.self_attn.language_expert_query_key_value.weight:  49%|████▉     | 39/79 [00:01<00:01, 21.66w/s, dev=0]model.layers.8.self_attn.rotary_emb.inv_freq:  51%|█████     | 40/79 [00:01<00:01, 21.72w/s, dev=0]                   model.layers.8.self_attn.vision_expert_dense.weight:  52%|█████▏    | 41/79 [00:01<00:01, 22.26w/s, dev=0]model.layers.8.self_attn.vision_expert_query_key_value.weight:  53%|█████▎    | 42/79 [00:01<00:01, 22.62w/s, dev=0]model.layers.8.self_attn.vision_expert_query_key_value.weight:  54%|█████▍    | 43/79 [00:01<00:01, 22.66w/s, dev=0]model.layers.9.input_layernorm.weight:  54%|█████▍    | 43/79 [00:01<00:01, 22.65w/s, dev=0]                        model.layers.9.mlp.language_mlp.down_proj.weight:  56%|█████▌    | 44/79 [00:01<00:01, 23.18w/s, dev=0]model.layers.9.mlp.language_mlp.gate_proj.weight:  57%|█████▋    | 45/79 [00:01<00:01, 23.26w/s, dev=0]model.layers.9.mlp.language_mlp.up_proj.weight:  58%|█████▊    | 46/79 [00:02<00:01, 20.87w/s, dev=0]  model.layers.9.mlp.vision_mlp.down_proj.weight:  59%|█████▉    | 47/79 [00:02<00:01, 20.96w/s, dev=0]model.layers.9.mlp.vision_mlp.gate_proj.weight:  61%|██████    | 48/79 [00:02<00:01, 21.05w/s, dev=0]model.layers.9.mlp.vision_mlp.gate_proj.weight:  62%|██████▏   | 49/79 [00:02<00:01, 21.14w/s, dev=0]model.layers.9.mlp.vision_mlp.up_proj.weight:  62%|██████▏   | 49/79 [00:02<00:01, 21.14w/s, dev=0]  model.layers.9.post_attention_layernorm.weight:  63%|██████▎   | 50/79 [00:02<00:01, 21.23w/s, dev=0]model.layers.9.self_attn.language_expert_dense.weight:  65%|██████▍   | 51/79 [00:02<00:01, 21.65w/s, dev=0]model.layers.9.self_attn.language_expert_query_key_value.weight:  66%|██████▌   | 52/79 [00:02<00:01, 21.95w/s, dev=0]model.layers.9.self_attn.rotary_emb.inv_freq:  67%|██████▋   | 53/79 [00:02<00:01, 21.49w/s, dev=0]                   model.layers.9.self_attn.vision_expert_dense.weight:  68%|██████▊   | 54/79 [00:02<00:01, 21.89w/s, dev=0]model.layers.9.self_attn.vision_expert_dense.weight:  70%|██████▉   | 55/79 [00:02<00:01, 22.18w/s, dev=0]model.layers.9.self_attn.vision_expert_query_key_value.weight:  70%|██████▉   | 55/79 [00:02<00:01, 22.18w/s, dev=0]model.layers.10.input_layernorm.weight:  71%|███████   | 56/79 [00:02<00:01, 22.23w/s, dev=0]                       model.layers.10.mlp.language_mlp.down_proj.weight:  72%|███████▏  | 57/79 [00:02<00:00, 22.61w/s, dev=0]model.layers.10.mlp.language_mlp.gate_proj.weight:  73%|███████▎  | 58/79 [00:02<00:01, 20.85w/s, dev=0]model.layers.10.mlp.language_mlp.up_proj.weight:  75%|███████▍  | 59/79 [00:02<00:00, 20.92w/s, dev=0]  model.layers.10.mlp.vision_mlp.down_proj.weight:  76%|███████▌  | 60/79 [00:02<00:00, 21.00w/s, dev=0]model.layers.10.mlp.vision_mlp.down_proj.weight:  77%|███████▋  | 61/79 [00:02<00:00, 21.07w/s, dev=0]model.layers.10.mlp.vision_mlp.gate_proj.weight:  77%|███████▋  | 61/79 [00:02<00:00, 21.07w/s, dev=0]model.layers.10.mlp.vision_mlp.up_proj.weight:  78%|███████▊  | 62/79 [00:02<00:00, 21.15w/s, dev=0]  model.layers.10.post_attention_layernorm.weight:  80%|███████▉  | 63/79 [00:02<00:00, 21.22w/s, dev=0]model.layers.10.self_attn.language_expert_dense.weight:  81%|████████  | 64/79 [00:02<00:00, 21.55w/s, dev=0]model.layers.10.self_attn.language_expert_query_key_value.weight:  82%|████████▏ | 65/79 [00:02<00:00, 21.78w/s, dev=0]model.layers.10.self_attn.rotary_emb.inv_freq:  84%|████████▎ | 66/79 [00:03<00:00, 21.38w/s, dev=0]                   model.layers.10.self_attn.rotary_emb.inv_freq:  85%|████████▍ | 67/79 [00:03<00:00, 21.71w/s, dev=0]model.layers.10.self_attn.vision_expert_dense.weight:  85%|████████▍ | 67/79 [00:03<00:00, 21.70w/s, dev=0]model.layers.10.self_attn.vision_expert_query_key_value.weight:  86%|████████▌ | 68/79 [00:03<00:00, 21.92w/s, dev=0]model.layers.11.mlp.language_mlp.down_proj.weight:  87%|████████▋ | 69/79 [00:03<00:00, 21.95w/s, dev=0]             model.layers.11.mlp.language_mlp.gate_proj.weight:  89%|████████▊ | 70/79 [00:03<00:00, 21.63w/s, dev=0]model.layers.11.mlp.language_mlp.up_proj.weight:  90%|████████▉ | 71/79 [00:03<00:00, 21.66w/s, dev=0]  model.layers.11.mlp.vision_mlp.gate_proj.weight:  91%|█████████ | 72/79 [00:03<00:00, 21.72w/s, dev=0]model.layers.11.mlp.vision_mlp.gate_proj.weight:  92%|█████████▏| 73/79 [00:03<00:00, 21.74w/s, dev=0]model.layers.11.mlp.vision_mlp.up_proj.weight:  92%|█████████▏| 73/79 [00:03<00:00, 21.74w/s, dev=0]  model.layers.11.self_attn.language_expert_dense.weight:  94%|█████████▎| 74/79 [00:03<00:00, 21.51w/s, dev=0]model.layers.11.self_attn.language_expert_query_key_value.weight:  95%|█████████▍| 75/79 [00:03<00:00, 21.49w/s, dev=0]model.layers.11.self_attn.rotary_emb.inv_freq:  96%|█████████▌| 76/79 [00:03<00:00, 21.18w/s, dev=0]                   model.layers.11.self_attn.vision_expert_dense.weight:  97%|█████████▋| 77/79 [00:03<00:00, 21.46w/s, dev=0]model.layers.11.self_attn.vision_expert_query_key_value.weight:  99%|█████████▊| 78/79 [00:03<00:00, 21.64w/s, dev=0]model.layers.11.self_attn.vision_expert_query_key_value.weight: 100%|██████████| 79/79 [00:03<00:00, 21.68w/s, dev=0]                                                                                                                       0%|          | 0/82 [00:00<?, ?w/s]model.layers.11.input_layernorm.weight:   0%|          | 0/82 [00:00<?, ?w/s, dev=0]model.layers.11.mlp.vision_mlp.down_proj.weight:   1%|          | 1/82 [00:00<00:00, 496.37w/s, dev=0]model.layers.11.mlp.vision_mlp.down_proj.weight:   2%|▏         | 2/82 [00:00<00:10,  7.77w/s, dev=0] model.layers.11.post_attention_layernorm.weight:   2%|▏         | 2/82 [00:00<00:10,  7.76w/s, dev=0]model.layers.12.input_layernorm.weight:   4%|▎         | 3/82 [00:00<00:06, 11.63w/s, dev=0]         model.layers.12.mlp.language_mlp.down_proj.weight:   5%|▍         | 4/82 [00:00<00:05, 15.49w/s, dev=0]model.layers.12.mlp.language_mlp.gate_proj.weight:   6%|▌         | 5/82 [00:00<00:04, 16.92w/s, dev=0]model.layers.12.mlp.language_mlp.up_proj.weight:   7%|▋         | 6/82 [00:00<00:04, 18.00w/s, dev=0]  model.layers.12.mlp.language_mlp.up_proj.weight:   9%|▊         | 7/82 [00:00<00:05, 13.96w/s, dev=0]model.layers.12.mlp.vision_mlp.down_proj.weight:   9%|▊         | 7/82 [00:00<00:05, 13.95w/s, dev=0]model.layers.12.mlp.vision_mlp.gate_proj.weight:  10%|▉         | 8/82 [00:00<00:04, 14.80w/s, dev=0]model.layers.12.mlp.vision_mlp.up_proj.weight:  11%|█         | 9/82 [00:00<00:04, 15.54w/s, dev=0]  model.layers.12.post_attention_layernorm.weight:  12%|█▏        | 10/82 [00:00<00:04, 16.20w/s, dev=0]model.layers.12.self_attn.language_expert_dense.weight:  13%|█▎        | 11/82 [00:00<00:03, 17.81w/s, dev=0]model.layers.12.self_attn.language_expert_dense.weight:  15%|█▍        | 12/82 [00:00<00:03, 18.99w/s, dev=0]model.layers.12.self_attn.language_expert_query_key_value.weight:  15%|█▍        | 12/82 [00:00<00:03, 18.98w/s, dev=0]model.layers.12.self_attn.rotary_emb.inv_freq:  16%|█▌        | 13/82 [00:00<00:03, 19.29w/s, dev=0]                   model.layers.12.self_attn.vision_expert_dense.weight:  17%|█▋        | 14/82 [00:00<00:03, 20.76w/s, dev=0]model.layers.12.self_attn.vision_expert_query_key_value.weight:  18%|█▊        | 15/82 [00:00<00:03, 21.78w/s, dev=0]model.layers.13.input_layernorm.weight:  20%|█▉        | 16/82 [00:00<00:03, 21.91w/s, dev=0]                        model.layers.13.mlp.language_mlp.down_proj.weight:  21%|██        | 17/82 [00:00<00:02, 23.27w/s, dev=0]model.layers.13.mlp.language_mlp.down_proj.weight:  22%|██▏       | 18/82 [00:00<00:02, 23.44w/s, dev=0]model.layers.13.mlp.language_mlp.gate_proj.weight:  22%|██▏       | 18/82 [00:00<00:02, 23.43w/s, dev=0]model.layers.13.mlp.language_mlp.up_proj.weight:  23%|██▎       | 19/82 [00:00<00:02, 23.59w/s, dev=0]  model.layers.13.mlp.vision_mlp.down_proj.weight:  24%|██▍       | 20/82 [00:00<00:02, 23.73w/s, dev=0]model.layers.13.mlp.vision_mlp.gate_proj.weight:  26%|██▌       | 21/82 [00:00<00:02, 23.85w/s, dev=0]model.layers.13.mlp.vision_mlp.up_proj.weight:  27%|██▋       | 22/82 [00:00<00:02, 23.97w/s, dev=0]  model.layers.13.post_attention_layernorm.weight:  28%|██▊       | 23/82 [00:00<00:02, 24.08w/s, dev=0]model.layers.13.post_attention_layernorm.weight:  29%|██▉       | 24/82 [00:00<00:02, 25.11w/s, dev=0]model.layers.13.self_attn.language_expert_dense.weight:  29%|██▉       | 24/82 [00:00<00:02, 25.11w/s, dev=0]model.layers.13.self_attn.language_expert_query_key_value.weight:  30%|███       | 25/82 [00:00<00:02, 25.78w/s, dev=0]model.layers.13.self_attn.rotary_emb.inv_freq:  32%|███▏      | 26/82 [00:01<00:02, 25.71w/s, dev=0]                   model.layers.13.self_attn.vision_expert_dense.weight:  33%|███▎      | 27/82 [00:01<00:02, 26.69w/s, dev=0]model.layers.13.self_attn.vision_expert_query_key_value.weight:  34%|███▍      | 28/82 [00:01<00:01, 27.30w/s, dev=0]model.layers.14.input_layernorm.weight:  35%|███▌      | 29/82 [00:01<00:02, 24.76w/s, dev=0]                        model.layers.14.input_layernorm.weight:  37%|███▋      | 30/82 [00:01<00:02, 25.61w/s, dev=0]model.layers.14.mlp.language_mlp.down_proj.weight:  37%|███▋      | 30/82 [00:01<00:02, 25.61w/s, dev=0]model.layers.14.mlp.language_mlp.gate_proj.weight:  38%|███▊      | 31/82 [00:01<00:01, 25.63w/s, dev=0]model.layers.14.mlp.language_mlp.up_proj.weight:  39%|███▉      | 32/82 [00:01<00:02, 23.54w/s, dev=0]  model.layers.14.mlp.vision_mlp.down_proj.weight:  40%|████      | 33/82 [00:01<00:02, 23.62w/s, dev=0]model.layers.14.mlp.vision_mlp.gate_proj.weight:  41%|████▏     | 34/82 [00:01<00:02, 23.70w/s, dev=0]model.layers.14.mlp.vision_mlp.up_proj.weight:  43%|████▎     | 35/82 [00:01<00:01, 23.77w/s, dev=0]  model.layers.14.mlp.vision_mlp.up_proj.weight:  44%|████▍     | 36/82 [00:01<00:01, 23.84w/s, dev=0]model.layers.14.post_attention_layernorm.weight:  44%|████▍     | 36/82 [00:01<00:01, 23.84w/s, dev=0]model.layers.14.self_attn.language_expert_dense.weight:  45%|████▌     | 37/82 [00:01<00:01, 24.50w/s, dev=0]model.layers.14.self_attn.language_expert_query_key_value.weight:  46%|████▋     | 38/82 [00:01<00:01, 24.92w/s, dev=0]model.layers.14.self_attn.rotary_emb.inv_freq:  48%|████▊     | 39/82 [00:01<00:01, 24.90w/s, dev=0]                   model.layers.14.self_attn.vision_expert_dense.weight:  49%|████▉     | 40/82 [00:01<00:01, 25.53w/s, dev=0]model.layers.14.self_attn.vision_expert_query_key_value.weight:  50%|█████     | 41/82 [00:01<00:01, 25.93w/s, dev=0]model.layers.14.self_attn.vision_expert_query_key_value.weight:  51%|█████     | 42/82 [00:01<00:01, 25.88w/s, dev=0]model.layers.15.input_layernorm.weight:  51%|█████     | 42/82 [00:01<00:01, 25.88w/s, dev=0]                        model.layers.15.mlp.language_mlp.down_proj.weight:  52%|█████▏    | 43/82 [00:01<00:01, 26.49w/s, dev=0]model.layers.15.mlp.language_mlp.gate_proj.weight:  54%|█████▎    | 44/82 [00:01<00:01, 26.50w/s, dev=0]model.layers.15.mlp.language_mlp.up_proj.weight:  55%|█████▍    | 45/82 [00:01<00:01, 26.51w/s, dev=0]  model.layers.15.mlp.vision_mlp.down_proj.weight:  56%|█████▌    | 46/82 [00:01<00:01, 26.51w/s, dev=0]model.layers.15.mlp.vision_mlp.gate_proj.weight:  57%|█████▋    | 47/82 [00:01<00:01, 26.51w/s, dev=0]model.layers.15.mlp.vision_mlp.gate_proj.weight:  59%|█████▊    | 48/82 [00:01<00:01, 26.52w/s, dev=0]model.layers.15.mlp.vision_mlp.up_proj.weight:  59%|█████▊    | 48/82 [00:01<00:01, 26.51w/s, dev=0]  model.layers.15.post_attention_layernorm.weight:  60%|█████▉    | 49/82 [00:01<00:01, 26.52w/s, dev=0]model.layers.15.self_attn.language_expert_dense.weight:  61%|██████    | 50/82 [00:01<00:01, 27.05w/s, dev=0]model.layers.15.self_attn.language_expert_query_key_value.weight:  62%|██████▏   | 51/82 [00:01<00:01, 27.38w/s, dev=0]model.layers.15.self_attn.rotary_emb.inv_freq:  63%|██████▎   | 52/82 [00:01<00:01, 27.31w/s, dev=0]                   model.layers.15.self_attn.vision_expert_dense.weight:  65%|██████▍   | 53/82 [00:01<00:01, 27.83w/s, dev=0]model.layers.15.self_attn.vision_expert_dense.weight:  66%|██████▌   | 54/82 [00:01<00:00, 28.14w/s, dev=0]model.layers.15.self_attn.vision_expert_query_key_value.weight:  66%|██████▌   | 54/82 [00:01<00:00, 28.13w/s, dev=0]model.layers.16.input_layernorm.weight:  67%|██████▋   | 55/82 [00:02<00:01, 26.33w/s, dev=0]                        model.layers.16.mlp.language_mlp.down_proj.weight:  68%|██████▊   | 56/82 [00:02<00:00, 26.80w/s, dev=0]model.layers.16.mlp.language_mlp.gate_proj.weight:  70%|██████▉   | 57/82 [00:02<00:00, 26.80w/s, dev=0]model.layers.16.mlp.language_mlp.up_proj.weight:  71%|███████   | 58/82 [00:02<00:00, 26.79w/s, dev=0]  model.layers.16.mlp.vision_mlp.down_proj.weight:  72%|███████▏  | 59/82 [00:02<00:00, 26.79w/s, dev=0]model.layers.16.mlp.vision_mlp.down_proj.weight:  73%|███████▎  | 60/82 [00:02<00:00, 26.79w/s, dev=0]model.layers.16.mlp.vision_mlp.gate_proj.weight:  73%|███████▎  | 60/82 [00:02<00:00, 26.79w/s, dev=0]model.layers.16.mlp.vision_mlp.up_proj.weight:  74%|███████▍  | 61/82 [00:02<00:00, 26.79w/s, dev=0]  model.layers.16.post_attention_layernorm.weight:  76%|███████▌  | 62/82 [00:02<00:00, 26.79w/s, dev=0]model.layers.16.self_attn.language_expert_dense.weight:  77%|███████▋  | 63/82 [00:02<00:00, 27.21w/s, dev=0]model.layers.16.self_attn.language_expert_query_key_value.weight:  78%|███████▊  | 64/82 [00:02<00:00, 27.48w/s, dev=0]model.layers.16.self_attn.rotary_emb.inv_freq:  79%|███████▉  | 65/82 [00:02<00:00, 27.41w/s, dev=0]                   model.layers.16.self_attn.rotary_emb.inv_freq:  80%|████████  | 66/82 [00:02<00:00, 27.83w/s, dev=0]model.layers.16.self_attn.vision_expert_dense.weight:  80%|████████  | 66/82 [00:02<00:00, 27.83w/s, dev=0]model.layers.16.self_attn.vision_expert_query_key_value.weight:  82%|████████▏ | 67/82 [00:02<00:00, 28.08w/s, dev=0]model.layers.17.input_layernorm.weight:  83%|████████▎ | 68/82 [00:02<00:00, 28.02w/s, dev=0]                        model.layers.17.mlp.language_mlp.down_proj.weight:  84%|████████▍ | 69/82 [00:02<00:00, 28.42w/s, dev=0]model.layers.17.mlp.language_mlp.gate_proj.weight:  85%|████████▌ | 70/82 [00:02<00:00, 26.93w/s, dev=0]model.layers.17.mlp.language_mlp.up_proj.weight:  87%|████████▋ | 71/82 [00:02<00:00, 26.92w/s, dev=0]  model.layers.17.mlp.language_mlp.up_proj.weight:  88%|████████▊ | 72/82 [00:02<00:00, 26.91w/s, dev=0]model.layers.17.mlp.vision_mlp.down_proj.weight:  88%|████████▊ | 72/82 [00:02<00:00, 26.90w/s, dev=0]model.layers.17.mlp.vision_mlp.gate_proj.weight:  89%|████████▉ | 73/82 [00:02<00:00, 26.90w/s, dev=0]model.layers.17.mlp.vision_mlp.up_proj.weight:  90%|█████████ | 74/82 [00:02<00:00, 26.89w/s, dev=0]  model.layers.17.post_attention_layernorm.weight:  91%|█████████▏| 75/82 [00:02<00:00, 26.88w/s, dev=0]model.layers.17.self_attn.language_expert_dense.weight:  93%|█████████▎| 76/82 [00:02<00:00, 27.24w/s, dev=0]model.layers.17.self_attn.language_expert_query_key_value.weight:  94%|█████████▍| 77/82 [00:02<00:00, 27.46w/s, dev=0]model.layers.17.self_attn.language_expert_query_key_value.weight:  95%|█████████▌| 78/82 [00:02<00:00, 27.42w/s, dev=0]model.layers.17.self_attn.rotary_emb.inv_freq:  95%|█████████▌| 78/82 [00:02<00:00, 27.41w/s, dev=0]                   model.layers.17.self_attn.vision_expert_dense.weight:  96%|█████████▋| 79/82 [00:02<00:00, 27.76w/s, dev=0]model.layers.17.self_attn.vision_expert_query_key_value.weight:  98%|█████████▊| 80/82 [00:02<00:00, 27.98w/s, dev=0]model.layers.18.self_attn.rotary_emb.inv_freq:  99%|█████████▉| 81/82 [00:02<00:00, 27.94w/s, dev=0]                                                                                                                       0%|          | 0/80 [00:00<?, ?w/s]model.layers.18.input_layernorm.weight:   0%|          | 0/80 [00:00<?, ?w/s, dev=0]model.layers.18.mlp.language_mlp.down_proj.weight:   1%|▏         | 1/80 [00:00<00:01, 53.00w/s, dev=0]model.layers.18.mlp.language_mlp.down_proj.weight:   2%|▎         | 2/80 [00:00<00:12,  6.32w/s, dev=0]model.layers.18.mlp.language_mlp.gate_proj.weight:   2%|▎         | 2/80 [00:00<00:12,  6.31w/s, dev=0]model.layers.18.mlp.language_mlp.up_proj.weight:   4%|▍         | 3/80 [00:00<00:12,  5.93w/s, dev=0]  model.layers.18.mlp.language_mlp.up_proj.weight:   5%|▌         | 4/80 [00:00<00:10,  7.35w/s, dev=0]model.layers.18.mlp.vision_mlp.down_proj.weight:   5%|▌         | 4/80 [00:00<00:10,  7.35w/s, dev=0]model.layers.18.mlp.vision_mlp.gate_proj.weight:   6%|▋         | 5/80 [00:00<00:08,  8.60w/s, dev=0]model.layers.18.mlp.vision_mlp.gate_proj.weight:   8%|▊         | 6/80 [00:00<00:09,  8.19w/s, dev=0]model.layers.18.mlp.vision_mlp.up_proj.weight:   8%|▊         | 6/80 [00:00<00:09,  8.19w/s, dev=0]  model.layers.18.post_attention_layernorm.weight:   9%|▉         | 7/80 [00:00<00:08,  9.08w/s, dev=0]model.layers.18.self_attn.language_expert_dense.weight:  10%|█         | 8/80 [00:00<00:06, 10.37w/s, dev=0]model.layers.18.self_attn.language_expert_query_key_value.weight:  11%|█▏        | 9/80 [00:00<00:06, 11.45w/s, dev=0]model.layers.18.self_attn.vision_expert_dense.weight:  12%|█▎        | 10/80 [00:00<00:05, 12.08w/s, dev=0]           model.layers.18.self_attn.vision_expert_dense.weight:  14%|█▍        | 11/80 [00:00<00:05, 13.06w/s, dev=0]model.layers.18.self_attn.vision_expert_query_key_value.weight:  14%|█▍        | 11/80 [00:00<00:05, 13.06w/s, dev=0]model.layers.19.input_layernorm.weight:  15%|█▌        | 12/80 [00:01<00:05, 11.81w/s, dev=0]                        model.layers.19.mlp.language_mlp.down_proj.weight:  16%|█▋        | 13/80 [00:01<00:05, 12.79w/s, dev=0]model.layers.19.mlp.language_mlp.gate_proj.weight:  18%|█▊        | 14/80 [00:01<00:04, 13.27w/s, dev=0]model.layers.19.mlp.language_mlp.up_proj.weight:  19%|█▉        | 15/80 [00:01<00:04, 13.73w/s, dev=0]  model.layers.19.mlp.language_mlp.up_proj.weight:  20%|██        | 16/80 [00:01<00:04, 14.16w/s, dev=0]model.layers.19.mlp.vision_mlp.down_proj.weight:  20%|██        | 16/80 [00:01<00:04, 14.16w/s, dev=0]model.layers.19.mlp.vision_mlp.gate_proj.weight:  21%|██▏       | 17/80 [00:01<00:04, 14.25w/s, dev=0]model.layers.19.mlp.vision_mlp.up_proj.weight:  22%|██▎       | 18/80 [00:01<00:04, 14.62w/s, dev=0]  model.layers.19.post_attention_layernorm.weight:  24%|██▍       | 19/80 [00:01<00:04, 14.97w/s, dev=0]model.layers.19.self_attn.language_expert_dense.weight:  25%|██▌       | 20/80 [00:01<00:03, 15.76w/s, dev=0]model.layers.19.self_attn.language_expert_dense.weight:  26%|██▋       | 21/80 [00:01<00:03, 14.85w/s, dev=0]model.layers.19.self_attn.language_expert_query_key_value.weight:  26%|██▋       | 21/80 [00:01<00:03, 14.85w/s, dev=0]model.layers.19.self_attn.rotary_emb.inv_freq:  28%|██▊       | 22/80 [00:01<00:03, 15.02w/s, dev=0]                   model.layers.19.self_attn.vision_expert_dense.weight:  29%|██▉       | 23/80 [00:01<00:03, 15.69w/s, dev=0]model.layers.19.self_attn.vision_expert_query_key_value.weight:  30%|███       | 24/80 [00:01<00:03, 16.22w/s, dev=0]model.layers.20.input_layernorm.weight:  31%|███▏      | 25/80 [00:01<00:03, 16.42w/s, dev=0]                        model.layers.20.input_layernorm.weight:  32%|███▎      | 26/80 [00:01<00:03, 17.07w/s, dev=0]model.layers.20.mlp.language_mlp.down_proj.weight:  32%|███▎      | 26/80 [00:01<00:03, 17.07w/s, dev=0]model.layers.20.mlp.language_mlp.gate_proj.weight:  34%|███▍      | 27/80 [00:01<00:03, 17.30w/s, dev=0]model.layers.20.mlp.language_mlp.up_proj.weight:  35%|███▌      | 28/80 [00:01<00:02, 17.53w/s, dev=0]  model.layers.20.mlp.vision_mlp.down_proj.weight:  36%|███▋      | 29/80 [00:01<00:02, 17.72w/s, dev=0]model.layers.20.mlp.vision_mlp.gate_proj.weight:  38%|███▊      | 30/80 [00:01<00:02, 17.69w/s, dev=0]model.layers.20.mlp.vision_mlp.gate_proj.weight:  39%|███▉      | 31/80 [00:01<00:02, 17.69w/s, dev=0]model.layers.20.mlp.vision_mlp.up_proj.weight:  39%|███▉      | 31/80 [00:01<00:02, 17.69w/s, dev=0]  model.layers.20.post_attention_layernorm.weight:  40%|████      | 32/80 [00:01<00:02, 17.71w/s, dev=0]model.layers.20.self_attn.language_expert_dense.weight:  41%|████▏     | 33/80 [00:01<00:02, 18.26w/s, dev=0]model.layers.20.self_attn.language_expert_query_key_value.weight:  42%|████▎     | 34/80 [00:01<00:02, 18.57w/s, dev=0]model.layers.20.self_attn.rotary_emb.inv_freq:  44%|████▍     | 35/80 [00:01<00:02, 18.02w/s, dev=0]                   model.layers.20.self_attn.rotary_emb.inv_freq:  45%|████▌     | 36/80 [00:01<00:02, 18.53w/s, dev=0]model.layers.20.self_attn.vision_expert_dense.weight:  45%|████▌     | 36/80 [00:01<00:02, 18.53w/s, dev=0]model.layers.20.self_attn.vision_expert_query_key_value.weight:  46%|████▋     | 37/80 [00:01<00:02, 18.91w/s, dev=0]model.layers.21.input_layernorm.weight:  48%|████▊     | 38/80 [00:02<00:02, 18.88w/s, dev=0]                        model.layers.21.mlp.language_mlp.down_proj.weight:  49%|████▉     | 39/80 [00:02<00:02, 19.37w/s, dev=0]model.layers.21.mlp.language_mlp.gate_proj.weight:  50%|█████     | 40/80 [00:02<00:02, 19.16w/s, dev=0]model.layers.21.mlp.language_mlp.gate_proj.weight:  51%|█████▏    | 41/80 [00:02<00:02, 19.12w/s, dev=0]model.layers.21.mlp.language_mlp.up_proj.weight:  51%|█████▏    | 41/80 [00:02<00:02, 19.11w/s, dev=0]  model.layers.21.mlp.vision_mlp.down_proj.weight:  52%|█████▎    | 42/80 [00:02<00:01, 19.03w/s, dev=0]model.layers.21.mlp.vision_mlp.gate_proj.weight:  54%|█████▍    | 43/80 [00:02<00:01, 18.92w/s, dev=0]model.layers.21.mlp.vision_mlp.up_proj.weight:  55%|█████▌    | 44/80 [00:02<00:01, 18.84w/s, dev=0]  model.layers.21.post_attention_layernorm.weight:  56%|█████▋    | 45/80 [00:02<00:01, 18.78w/s, dev=0]model.layers.21.post_attention_layernorm.weight:  57%|█████▊    | 46/80 [00:02<00:01, 19.19w/s, dev=0]model.layers.21.self_attn.language_expert_dense.weight:  57%|█████▊    | 46/80 [00:02<00:01, 19.19w/s, dev=0]model.layers.21.self_attn.language_expert_query_key_value.weight:  59%|█████▉    | 47/80 [00:02<00:01, 19.43w/s, dev=0]model.layers.21.self_attn.rotary_emb.inv_freq:  60%|██████    | 48/80 [00:02<00:01, 19.33w/s, dev=0]                   model.layers.21.self_attn.vision_expert_dense.weight:  61%|██████▏   | 49/80 [00:02<00:01, 19.73w/s, dev=0]model.layers.21.self_attn.vision_expert_query_key_value.weight:  62%|██████▎   | 50/80 [00:02<00:01, 19.97w/s, dev=0]model.layers.21.self_attn.vision_expert_query_key_value.weight:  64%|██████▍   | 51/80 [00:02<00:01, 19.85w/s, dev=0]model.layers.22.input_layernorm.weight:  64%|██████▍   | 51/80 [00:02<00:01, 19.85w/s, dev=0]                        model.layers.22.mlp.language_mlp.down_proj.weight:  65%|██████▌   | 52/80 [00:02<00:01, 20.24w/s, dev=0]model.layers.22.mlp.language_mlp.gate_proj.weight:  66%|██████▋   | 53/80 [00:02<00:01, 20.20w/s, dev=0]model.layers.22.mlp.language_mlp.up_proj.weight:  68%|██████▊   | 54/80 [00:02<00:01, 20.17w/s, dev=0]  model.layers.22.mlp.vision_mlp.down_proj.weight:  69%|██████▉   | 55/80 [00:02<00:01, 20.11w/s, dev=0]model.layers.22.mlp.vision_mlp.down_proj.weight:  70%|███████   | 56/80 [00:02<00:01, 20.07w/s, dev=0]model.layers.22.mlp.vision_mlp.gate_proj.weight:  70%|███████   | 56/80 [00:02<00:01, 20.07w/s, dev=0]model.layers.22.mlp.vision_mlp.up_proj.weight:  71%|███████▏  | 57/80 [00:02<00:01, 19.97w/s, dev=0]  model.layers.22.post_attention_layernorm.weight:  72%|███████▎  | 58/80 [00:02<00:01, 19.94w/s, dev=0]model.layers.22.self_attn.language_expert_dense.weight:  74%|███████▍  | 59/80 [00:02<00:01, 20.28w/s, dev=0]model.layers.22.self_attn.language_expert_query_key_value.weight:  75%|███████▌  | 60/80 [00:02<00:00, 20.49w/s, dev=0]model.layers.22.self_attn.language_expert_query_key_value.weight:  76%|███████▋  | 61/80 [00:02<00:00, 20.39w/s, dev=0]model.layers.22.self_attn.rotary_emb.inv_freq:  76%|███████▋  | 61/80 [00:03<00:00, 20.23w/s, dev=0]                   model.layers.22.self_attn.vision_expert_dense.weight:  78%|███████▊  | 62/80 [00:03<00:00, 20.56w/s, dev=0]model.layers.22.self_attn.vision_expert_query_key_value.weight:  79%|███████▉  | 63/80 [00:03<00:00, 20.78w/s, dev=0]model.layers.23.input_layernorm.weight:  80%|████████  | 64/80 [00:03<00:00, 20.75w/s, dev=0]                        model.layers.23.mlp.language_mlp.down_proj.weight:  81%|████████▏ | 65/80 [00:03<00:00, 21.07w/s, dev=0]model.layers.23.mlp.language_mlp.down_proj.weight:  82%|████████▎ | 66/80 [00:03<00:00, 21.04w/s, dev=0]model.layers.23.mlp.language_mlp.gate_proj.weight:  82%|████████▎ | 66/80 [00:03<00:00, 21.04w/s, dev=0]model.layers.23.mlp.language_mlp.up_proj.weight:  84%|████████▍ | 67/80 [00:03<00:00, 20.97w/s, dev=0]  model.layers.23.mlp.vision_mlp.down_proj.weight:  85%|████████▌ | 68/80 [00:03<00:00, 20.92w/s, dev=0]model.layers.23.mlp.vision_mlp.gate_proj.weight:  86%|████████▋ | 69/80 [00:03<00:00, 20.83w/s, dev=0]model.layers.23.mlp.vision_mlp.up_proj.weight:  88%|████████▊ | 70/80 [00:03<00:00, 20.79w/s, dev=0]  model.layers.23.mlp.vision_mlp.up_proj.weight:  89%|████████▉ | 71/80 [00:03<00:00, 20.70w/s, dev=0]model.layers.23.post_attention_layernorm.weight:  89%|████████▉ | 71/80 [00:03<00:00, 20.70w/s, dev=0]model.layers.23.self_attn.language_expert_dense.weight:  90%|█████████ | 72/80 [00:03<00:00, 20.99w/s, dev=0]model.layers.23.self_attn.language_expert_query_key_value.weight:  91%|█████████▏| 73/80 [00:03<00:00, 21.16w/s, dev=0]model.layers.23.self_attn.rotary_emb.inv_freq:  92%|█████████▎| 74/80 [00:03<00:00, 21.06w/s, dev=0]                   model.layers.23.self_attn.vision_expert_dense.weight:  94%|█████████▍| 75/80 [00:03<00:00, 21.34w/s, dev=0]model.layers.23.self_attn.vision_expert_dense.weight:  95%|█████████▌| 76/80 [00:03<00:00, 21.49w/s, dev=0]model.layers.23.self_attn.vision_expert_query_key_value.weight:  95%|█████████▌| 76/80 [00:03<00:00, 21.49w/s, dev=0]model.layers.24.self_attn.rotary_emb.inv_freq:  96%|█████████▋| 77/80 [00:03<00:00, 21.42w/s, dev=0]                 model.layers.24.self_attn.vision_expert_dense.weight:  98%|█████████▊| 78/80 [00:03<00:00, 21.70w/s, dev=0]model.layers.24.self_attn.vision_expert_query_key_value.weight:  99%|█████████▉| 79/80 [00:03<00:00, 21.84w/s, dev=0]                                                                                                                       0%|          | 0/80 [00:00<?, ?w/s]model.layers.24.input_layernorm.weight:   0%|          | 0/80 [00:00<?, ?w/s, dev=0]model.layers.24.mlp.language_mlp.down_proj.weight:   1%|▏         | 1/80 [00:00<00:00, 532.68w/s, dev=0]model.layers.24.mlp.language_mlp.down_proj.weight:   2%|▎         | 2/80 [00:00<00:07, 10.12w/s, dev=0] model.layers.24.mlp.language_mlp.gate_proj.weight:   2%|▎         | 2/80 [00:00<00:07, 10.11w/s, dev=0]model.layers.24.mlp.language_mlp.up_proj.weight:   4%|▍         | 3/80 [00:00<00:06, 12.81w/s, dev=0]  model.layers.24.mlp.language_mlp.up_proj.weight:   5%|▌         | 4/80 [00:00<00:05, 13.41w/s, dev=0]model.layers.24.mlp.vision_mlp.down_proj.weight:   5%|▌         | 4/80 [00:00<00:05, 13.40w/s, dev=0]model.layers.24.mlp.vision_mlp.gate_proj.weight:   6%|▋         | 5/80 [00:00<00:05, 13.77w/s, dev=0]model.layers.24.mlp.vision_mlp.gate_proj.weight:   8%|▊         | 6/80 [00:00<00:05, 13.91w/s, dev=0]model.layers.24.mlp.vision_mlp.up_proj.weight:   8%|▊         | 6/80 [00:00<00:05, 13.90w/s, dev=0]  model.layers.24.post_attention_layernorm.weight:   9%|▉         | 7/80 [00:00<00:05, 14.23w/s, dev=0]model.layers.24.self_attn.language_expert_dense.weight:  10%|█         | 8/80 [00:00<00:04, 16.25w/s, dev=0]model.layers.24.self_attn.language_expert_query_key_value.weight:  11%|█▏        | 9/80 [00:00<00:04, 17.41w/s, dev=0]model.layers.24.self_attn.language_expert_query_key_value.weight:  12%|█▎        | 10/80 [00:00<00:04, 16.76w/s, dev=0]model.layers.25.input_layernorm.weight:  12%|█▎        | 10/80 [00:00<00:04, 16.36w/s, dev=1]                          model.layers.25.mlp.language_mlp.down_proj.weight:  14%|█▍        | 11/80 [00:00<00:05, 13.42w/s, dev=1]model.layers.25.mlp.language_mlp.gate_proj.weight:  15%|█▌        | 12/80 [00:00<00:04, 13.75w/s, dev=1]model.layers.25.mlp.language_mlp.up_proj.weight:  16%|█▋        | 13/80 [00:00<00:04, 14.30w/s, dev=1]  model.layers.25.mlp.language_mlp.up_proj.weight:  18%|█▊        | 14/80 [00:00<00:04, 14.81w/s, dev=1]model.layers.25.mlp.vision_mlp.down_proj.weight:  18%|█▊        | 14/80 [00:00<00:04, 14.81w/s, dev=1]model.layers.25.mlp.vision_mlp.gate_proj.weight:  19%|█▉        | 15/80 [00:00<00:04, 15.28w/s, dev=1]model.layers.25.mlp.vision_mlp.up_proj.weight:  20%|██        | 16/80 [00:01<00:04, 15.50w/s, dev=1]  model.layers.25.post_attention_layernorm.weight:  21%|██▏       | 17/80 [00:01<00:03, 15.91w/s, dev=1]model.layers.25.post_attention_layernorm.weight:  22%|██▎       | 18/80 [00:01<00:03, 16.84w/s, dev=1]model.layers.25.self_attn.language_expert_dense.weight:  22%|██▎       | 18/80 [00:01<00:03, 16.84w/s, dev=1]model.layers.25.self_attn.language_expert_query_key_value.weight:  24%|██▍       | 19/80 [00:01<00:03, 17.54w/s, dev=1]model.layers.25.self_attn.rotary_emb.inv_freq:  25%|██▌       | 20/80 [00:01<00:03, 17.81w/s, dev=1]                   model.layers.25.self_attn.vision_expert_dense.weight:  26%|██▋       | 21/80 [00:01<00:03, 18.69w/s, dev=1]model.layers.25.self_attn.vision_expert_query_key_value.weight:  28%|██▊       | 22/80 [00:01<00:02, 19.35w/s, dev=1]model.layers.25.self_attn.vision_expert_query_key_value.weight:  29%|██▉       | 23/80 [00:01<00:02, 19.06w/s, dev=1]model.layers.26.input_layernorm.weight:  29%|██▉       | 23/80 [00:01<00:02, 19.06w/s, dev=1]                        model.layers.26.mlp.language_mlp.down_proj.weight:  30%|███       | 24/80 [00:01<00:02, 19.88w/s, dev=1]model.layers.26.mlp.language_mlp.gate_proj.weight:  31%|███▏      | 25/80 [00:01<00:02, 19.85w/s, dev=1]model.layers.26.mlp.language_mlp.up_proj.weight:  32%|███▎      | 26/80 [00:01<00:02, 18.79w/s, dev=1]  model.layers.26.mlp.vision_mlp.down_proj.weight:  34%|███▍      | 27/80 [00:01<00:02, 18.59w/s, dev=1]model.layers.26.mlp.vision_mlp.down_proj.weight:  35%|███▌      | 28/80 [00:01<00:02, 18.08w/s, dev=1]model.layers.26.mlp.vision_mlp.gate_proj.weight:  35%|███▌      | 28/80 [00:01<00:02, 18.08w/s, dev=1]model.layers.26.mlp.vision_mlp.up_proj.weight:  36%|███▋      | 29/80 [00:01<00:02, 17.56w/s, dev=1]  model.layers.26.post_attention_layernorm.weight:  38%|███▊      | 30/80 [00:01<00:02, 17.32w/s, dev=1]model.layers.26.self_attn.language_expert_dense.weight:  39%|███▉      | 31/80 [00:01<00:02, 17.89w/s, dev=1]model.layers.26.self_attn.language_expert_query_key_value.weight:  40%|████      | 32/80 [00:01<00:02, 17.94w/s, dev=1]model.layers.26.self_attn.language_expert_query_key_value.weight:  41%|████▏     | 33/80 [00:01<00:02, 17.96w/s, dev=1]model.layers.26.self_attn.rotary_emb.inv_freq:  41%|████▏     | 33/80 [00:01<00:02, 17.96w/s, dev=1]                   model.layers.26.self_attn.vision_expert_dense.weight:  42%|████▎     | 34/80 [00:01<00:02, 18.50w/s, dev=1]model.layers.26.self_attn.vision_expert_query_key_value.weight:  44%|████▍     | 35/80 [00:01<00:02, 18.75w/s, dev=1]model.layers.27.input_layernorm.weight:  45%|████▌     | 36/80 [00:01<00:02, 18.58w/s, dev=1]                        model.layers.27.mlp.language_mlp.down_proj.weight:  46%|████▋     | 37/80 [00:01<00:02, 19.10w/s, dev=1]model.layers.27.mlp.language_mlp.down_proj.weight:  48%|████▊     | 38/80 [00:02<00:02, 18.64w/s, dev=1]model.layers.27.mlp.language_mlp.gate_proj.weight:  48%|████▊     | 38/80 [00:02<00:02, 18.64w/s, dev=1]model.layers.27.mlp.language_mlp.up_proj.weight:  49%|████▉     | 39/80 [00:02<00:02, 18.40w/s, dev=1]  model.layers.27.mlp.vision_mlp.down_proj.weight:  50%|█████     | 40/80 [00:02<00:02, 18.36w/s, dev=1]model.layers.27.mlp.vision_mlp.gate_proj.weight:  51%|█████▏    | 41/80 [00:02<00:02, 18.17w/s, dev=1]model.layers.27.mlp.vision_mlp.up_proj.weight:  52%|█████▎    | 42/80 [00:02<00:02, 18.13w/s, dev=1]  model.layers.27.mlp.vision_mlp.up_proj.weight:  54%|█████▍    | 43/80 [00:02<00:02, 18.03w/s, dev=1]model.layers.27.post_attention_layernorm.weight:  54%|█████▍    | 43/80 [00:02<00:02, 18.03w/s, dev=1]model.layers.27.self_attn.language_expert_dense.weight:  55%|█████▌    | 44/80 [00:02<00:01, 18.45w/s, dev=1]model.layers.27.self_attn.language_expert_query_key_value.weight:  56%|█████▋    | 45/80 [00:02<00:01, 18.57w/s, dev=1]model.layers.27.self_attn.rotary_emb.inv_freq:  57%|█████▊    | 46/80 [00:02<00:01, 18.19w/s, dev=1]                   model.layers.27.self_attn.vision_expert_dense.weight:  59%|█████▉    | 47/80 [00:02<00:01, 18.59w/s, dev=1]model.layers.27.self_attn.vision_expert_dense.weight:  60%|██████    | 48/80 [00:02<00:01, 18.74w/s, dev=1]model.layers.27.self_attn.vision_expert_query_key_value.weight:  60%|██████    | 48/80 [00:02<00:01, 18.74w/s, dev=1]model.layers.28.input_layernorm.weight:  61%|██████▏   | 49/80 [00:02<00:01, 18.19w/s, dev=1]                        model.layers.28.mlp.language_mlp.down_proj.weight:  62%|██████▎   | 50/80 [00:02<00:01, 18.56w/s, dev=1]model.layers.28.mlp.language_mlp.gate_proj.weight:  64%|██████▍   | 51/80 [00:02<00:01, 18.51w/s, dev=1]model.layers.28.mlp.language_mlp.up_proj.weight:  65%|██████▌   | 52/80 [00:02<00:01, 18.43w/s, dev=1]  model.layers.28.mlp.language_mlp.up_proj.weight:  66%|██████▋   | 53/80 [00:02<00:01, 18.38w/s, dev=1]model.layers.28.mlp.vision_mlp.down_proj.weight:  66%|██████▋   | 53/80 [00:02<00:01, 18.38w/s, dev=1]model.layers.28.mlp.vision_mlp.gate_proj.weight:  68%|██████▊   | 54/80 [00:02<00:01, 18.32w/s, dev=1]model.layers.28.mlp.vision_mlp.up_proj.weight:  69%|██████▉   | 55/80 [00:03<00:01, 18.28w/s, dev=1]  model.layers.28.post_attention_layernorm.weight:  70%|███████   | 56/80 [00:03<00:01, 18.22w/s, dev=1]model.layers.28.self_attn.language_expert_dense.weight:  71%|███████▏  | 57/80 [00:03<00:01, 18.55w/s, dev=1]model.layers.28.self_attn.language_expert_dense.weight:  72%|███████▎  | 58/80 [00:03<00:01, 18.72w/s, dev=1]model.layers.28.self_attn.language_expert_query_key_value.weight:  72%|███████▎  | 58/80 [00:03<00:01, 18.71w/s, dev=1]model.layers.28.self_attn.rotary_emb.inv_freq:  74%|███████▍  | 59/80 [00:03<00:01, 18.59w/s, dev=1]                   model.layers.28.self_attn.vision_expert_dense.weight:  75%|███████▌  | 60/80 [00:03<00:01, 18.90w/s, dev=1]model.layers.28.self_attn.vision_expert_query_key_value.weight:  76%|███████▋  | 61/80 [00:03<00:00, 19.07w/s, dev=1]model.layers.29.input_layernorm.weight:  78%|███████▊  | 62/80 [00:03<00:00, 18.92w/s, dev=1]                        model.layers.29.input_layernorm.weight:  79%|███████▉  | 63/80 [00:03<00:00, 19.22w/s, dev=1]model.layers.29.mlp.language_mlp.down_proj.weight:  79%|███████▉  | 63/80 [00:03<00:00, 19.22w/s, dev=1]model.layers.29.mlp.language_mlp.gate_proj.weight:  80%|████████  | 64/80 [00:03<00:00, 19.17w/s, dev=1]model.layers.29.mlp.language_mlp.up_proj.weight:  81%|████████▏ | 65/80 [00:03<00:00, 19.02w/s, dev=1]  model.layers.29.mlp.vision_mlp.down_proj.weight:  82%|████████▎ | 66/80 [00:03<00:00, 18.62w/s, dev=1]model.layers.29.mlp.vision_mlp.gate_proj.weight:  84%|████████▍ | 67/80 [00:03<00:00, 18.35w/s, dev=1]model.layers.29.mlp.vision_mlp.gate_proj.weight:  85%|████████▌ | 68/80 [00:03<00:00, 18.21w/s, dev=1]model.layers.29.mlp.vision_mlp.up_proj.weight:  85%|████████▌ | 68/80 [00:03<00:00, 18.21w/s, dev=1]  model.layers.29.post_attention_layernorm.weight:  86%|████████▋ | 69/80 [00:03<00:00, 18.14w/s, dev=1]model.layers.29.self_attn.language_expert_dense.weight:  88%|████████▊ | 70/80 [00:03<00:00, 18.40w/s, dev=1]model.layers.29.self_attn.language_expert_query_key_value.weight:  89%|████████▉ | 71/80 [00:03<00:00, 18.45w/s, dev=1]model.layers.29.self_attn.rotary_emb.inv_freq:  90%|█████████ | 72/80 [00:03<00:00, 18.28w/s, dev=1]                   model.layers.29.self_attn.rotary_emb.inv_freq:  91%|█████████▏| 73/80 [00:03<00:00, 18.53w/s, dev=1]model.layers.29.self_attn.vision_expert_dense.weight:  91%|█████████▏| 73/80 [00:03<00:00, 18.53w/s, dev=1]model.layers.29.self_attn.vision_expert_query_key_value.weight:  92%|█████████▎| 74/80 [00:03<00:00, 18.56w/s, dev=1]model.layers.30.self_attn.language_expert_dense.weight:  94%|█████████▍| 75/80 [00:04<00:00, 18.18w/s, dev=1]        model.layers.30.self_attn.language_expert_query_key_value.weight:  95%|█████████▌| 76/80 [00:04<00:00, 18.35w/s, dev=1]model.layers.30.self_attn.rotary_emb.inv_freq:  96%|█████████▋| 77/80 [00:04<00:00, 18.26w/s, dev=1]                   model.layers.30.self_attn.rotary_emb.inv_freq:  98%|█████████▊| 78/80 [00:04<00:00, 18.49w/s, dev=1]model.layers.30.self_attn.vision_expert_dense.weight:  98%|█████████▊| 78/80 [00:04<00:00, 18.49w/s, dev=1]model.layers.30.self_attn.vision_expert_query_key_value.weight:  99%|█████████▉| 79/80 [00:04<00:00, 18.65w/s, dev=1]                                                                                                                       0%|          | 0/348 [00:00<?, ?w/s]model.layers.30.input_layernorm.weight:   0%|          | 0/348 [00:00<?, ?w/s, dev=1]model.layers.30.mlp.language_mlp.down_proj.weight:   0%|          | 1/348 [00:00<00:00, 819.52w/s, dev=1]model.layers.30.mlp.language_mlp.down_proj.weight:   1%|          | 2/348 [00:00<00:35,  9.87w/s, dev=1] model.layers.30.mlp.language_mlp.gate_proj.weight:   1%|          | 2/348 [00:00<00:35,  9.86w/s, dev=1]model.layers.30.mlp.language_mlp.up_proj.weight:   1%|          | 3/348 [00:00<00:27, 12.49w/s, dev=1]  model.layers.30.mlp.vision_mlp.down_proj.weight:   1%|          | 4/348 [00:00<00:23, 14.49w/s, dev=1]model.layers.30.mlp.vision_mlp.down_proj.weight:   1%|▏         | 5/348 [00:00<00:22, 15.42w/s, dev=1]model.layers.30.mlp.vision_mlp.gate_proj.weight:   1%|▏         | 5/348 [00:00<00:22, 15.41w/s, dev=1]model.layers.30.mlp.vision_mlp.up_proj.weight:   2%|▏         | 6/348 [00:00<00:21, 15.69w/s, dev=1]  model.layers.30.post_attention_layernorm.weight:   2%|▏         | 7/348 [00:00<00:21, 15.91w/s, dev=1]model.layers.30.post_attention_layernorm.weight:   2%|▏         | 8/348 [00:00<00:18, 18.16w/s, dev=1]model.layers.31.input_layernorm.weight:   2%|▏         | 8/348 [00:00<00:18, 18.16w/s, dev=1]         model.layers.31.mlp.language_mlp.down_proj.weight:   3%|▎         | 9/348 [00:00<00:16, 20.42w/s, dev=1]model.layers.31.mlp.language_mlp.gate_proj.weight:   3%|▎         | 10/348 [00:00<00:16, 20.98w/s, dev=1]model.layers.31.mlp.language_mlp.up_proj.weight:   3%|▎         | 11/348 [00:00<00:16, 20.94w/s, dev=1]  model.layers.31.mlp.language_mlp.up_proj.weight:   3%|▎         | 12/348 [00:00<00:16, 21.00w/s, dev=1]model.layers.31.mlp.vision_mlp.down_proj.weight:   3%|▎         | 12/348 [00:00<00:16, 20.99w/s, dev=1]model.layers.31.mlp.vision_mlp.gate_proj.weight:   4%|▎         | 13/348 [00:00<00:15, 21.01w/s, dev=1]model.layers.31.mlp.vision_mlp.up_proj.weight:   4%|▍         | 14/348 [00:00<00:15, 21.13w/s, dev=1]  model.layers.31.post_attention_layernorm.weight:   4%|▍         | 15/348 [00:00<00:15, 21.08w/s, dev=1]model.layers.31.post_attention_layernorm.weight:   5%|▍         | 16/348 [00:00<00:14, 22.48w/s, dev=1]model.layers.31.self_attn.language_expert_dense.weight:   5%|▍         | 16/348 [00:00<00:14, 22.47w/s, dev=1]model.layers.31.self_attn.language_expert_query_key_value.weight:   5%|▍         | 17/348 [00:00<00:14, 23.28w/s, dev=1]model.layers.31.self_attn.rotary_emb.inv_freq:   5%|▌         | 18/348 [00:00<00:14, 22.95w/s, dev=1]                   model.layers.31.self_attn.vision_expert_dense.weight:   5%|▌         | 19/348 [00:00<00:13, 24.21w/s, dev=1]model.layers.31.self_attn.vision_expert_query_key_value.weight:   6%|▌         | 20/348 [00:00<00:13, 24.78w/s, dev=1]model.layers.31.self_attn.vision_expert_query_key_value.weight:   6%|▌         | 21/348 [00:00<00:13, 24.58w/s, dev=1]model.norm.weight:   6%|▌         | 21/348 [00:00<00:13, 24.58w/s, dev=1]                                             model.vision.boi:   6%|▋         | 22/348 [00:00<00:12, 25.74w/s, dev=1] model.vision.eoi:   7%|▋         | 23/348 [00:00<00:12, 26.90w/s, dev=1]model.vision.patch_embedding.cls_embedding:   7%|▋         | 24/348 [00:00<00:11, 28.07w/s, dev=1]model.vision.patch_embedding.position_embedding.weight:   7%|▋         | 25/348 [00:00<00:11, 29.23w/s, dev=1]model.vision.patch_embedding.proj.bias:   7%|▋         | 26/348 [00:00<00:10, 30.32w/s, dev=1]                model.vision.patch_embedding.proj.weight:   8%|▊         | 27/348 [00:00<00:10, 31.48w/s, dev=1]model.vision.transformer.layers.0.attention.dense.bias:   8%|▊         | 28/348 [00:00<00:09, 32.60w/s, dev=1]model.vision.transformer.layers.0.attention.dense.weight:   8%|▊         | 29/348 [00:00<00:09, 33.76w/s, dev=1]model.vision.transformer.layers.0.attention.query_key_value.bias:   9%|▊         | 30/348 [00:00<00:09, 34.67w/s, dev=1]model.vision.transformer.layers.0.attention.query_key_value.weight:   9%|▉         | 31/348 [00:00<00:08, 35.82w/s, dev=1]model.vision.transformer.layers.0.input_layernorm.bias:   9%|▉         | 32/348 [00:00<00:08, 36.66w/s, dev=1]            model.vision.transformer.layers.0.input_layernorm.weight:   9%|▉         | 33/348 [00:00<00:08, 37.80w/s, dev=1]model.vision.transformer.layers.0.mlp.fc1.bias:  10%|▉         | 34/348 [00:00<00:08, 38.93w/s, dev=1]          model.vision.transformer.layers.0.mlp.fc1.weight:  10%|█         | 35/348 [00:00<00:07, 40.07w/s, dev=1]model.vision.transformer.layers.0.mlp.fc2.bias:  10%|█         | 36/348 [00:00<00:07, 39.91w/s, dev=1]  model.vision.transformer.layers.0.mlp.fc2.weight:  11%|█         | 37/348 [00:00<00:07, 41.00w/s, dev=1]model.vision.transformer.layers.0.post_attention_layernorm.bias:  11%|█         | 38/348 [00:00<00:07, 40.77w/s, dev=1]model.vision.transformer.layers.0.post_attention_layernorm.weight:  11%|█         | 39/348 [00:00<00:07, 41.82w/s, dev=1]model.vision.transformer.layers.1.attention.dense.bias:  11%|█▏        | 40/348 [00:00<00:07, 42.89w/s, dev=1]           model.vision.transformer.layers.1.attention.dense.weight:  12%|█▏        | 41/348 [00:00<00:06, 43.95w/s, dev=1]model.vision.transformer.layers.1.attention.query_key_value.bias:  12%|█▏        | 42/348 [00:00<00:06, 44.70w/s, dev=1]model.vision.transformer.layers.1.attention.query_key_value.weight:  12%|█▏        | 43/348 [00:00<00:06, 45.75w/s, dev=1]model.vision.transformer.layers.1.input_layernorm.bias:  13%|█▎        | 44/348 [00:00<00:06, 46.44w/s, dev=1]            model.vision.transformer.layers.1.input_layernorm.weight:  13%|█▎        | 45/348 [00:00<00:06, 47.48w/s, dev=1]model.vision.transformer.layers.1.mlp.fc1.bias:  13%|█▎        | 46/348 [00:00<00:06, 48.53w/s, dev=1]          model.vision.transformer.layers.1.mlp.fc1.weight:  14%|█▎        | 47/348 [00:00<00:06, 49.58w/s, dev=1]model.vision.transformer.layers.1.mlp.fc1.weight:  14%|█▍        | 48/348 [00:00<00:06, 49.08w/s, dev=1]model.vision.transformer.layers.1.mlp.fc2.bias:  14%|█▍        | 48/348 [00:00<00:06, 49.07w/s, dev=1]  model.vision.transformer.layers.1.mlp.fc2.weight:  14%|█▍        | 49/348 [00:00<00:05, 50.07w/s, dev=1]model.vision.transformer.layers.1.post_attention_layernorm.bias:  14%|█▍        | 50/348 [00:01<00:06, 49.58w/s, dev=1]model.vision.transformer.layers.1.post_attention_layernorm.weight:  15%|█▍        | 51/348 [00:01<00:05, 50.55w/s, dev=1]model.vision.transformer.layers.10.attention.dense.bias:  15%|█▍        | 52/348 [00:01<00:05, 51.53w/s, dev=1]          model.vision.transformer.layers.10.attention.dense.weight:  15%|█▌        | 53/348 [00:01<00:05, 52.52w/s, dev=1]model.vision.transformer.layers.10.attention.query_key_value.bias:  16%|█▌        | 54/348 [00:01<00:05, 53.35w/s, dev=1]model.vision.transformer.layers.10.attention.query_key_value.weight:  16%|█▌        | 55/348 [00:01<00:05, 54.32w/s, dev=1]model.vision.transformer.layers.10.input_layernorm.bias:  16%|█▌        | 56/348 [00:01<00:05, 54.74w/s, dev=1]            model.vision.transformer.layers.10.input_layernorm.weight:  16%|█▋        | 57/348 [00:01<00:05, 55.70w/s, dev=1]model.vision.transformer.layers.10.mlp.fc1.bias:  17%|█▋        | 58/348 [00:01<00:05, 56.67w/s, dev=1]          model.vision.transformer.layers.10.mlp.fc1.weight:  17%|█▋        | 59/348 [00:01<00:05, 57.63w/s, dev=1]model.vision.transformer.layers.10.mlp.fc2.bias:  17%|█▋        | 60/348 [00:01<00:05, 56.33w/s, dev=1]  model.vision.transformer.layers.10.mlp.fc2.weight:  18%|█▊        | 61/348 [00:01<00:05, 57.25w/s, dev=1]model.vision.transformer.layers.10.post_attention_layernorm.bias:  18%|█▊        | 62/348 [00:01<00:05, 55.50w/s, dev=1]model.vision.transformer.layers.10.post_attention_layernorm.weight:  18%|█▊        | 63/348 [00:01<00:05, 56.37w/s, dev=1]model.vision.transformer.layers.11.attention.dense.bias:  18%|█▊        | 64/348 [00:01<00:04, 57.25w/s, dev=1]           model.vision.transformer.layers.11.attention.dense.weight:  19%|█▊        | 65/348 [00:01<00:04, 58.14w/s, dev=1]model.vision.transformer.layers.11.attention.query_key_value.bias:  19%|█▉        | 66/348 [00:01<00:04, 58.89w/s, dev=1]model.vision.transformer.layers.11.attention.query_key_value.weight:  19%|█▉        | 67/348 [00:01<00:04, 59.77w/s, dev=1]model.vision.transformer.layers.11.input_layernorm.bias:  20%|█▉        | 68/348 [00:01<00:04, 59.87w/s, dev=1]            model.vision.transformer.layers.11.input_layernorm.weight:  20%|█▉        | 69/348 [00:01<00:04, 60.73w/s, dev=1]model.vision.transformer.layers.11.mlp.fc1.bias:  20%|██        | 70/348 [00:01<00:04, 61.60w/s, dev=1]          model.vision.transformer.layers.11.mlp.fc1.weight:  20%|██        | 71/348 [00:01<00:04, 62.47w/s, dev=1]model.vision.transformer.layers.11.mlp.fc2.bias:  21%|██        | 72/348 [00:01<00:04, 61.68w/s, dev=1]  model.vision.transformer.layers.11.mlp.fc2.weight:  21%|██        | 73/348 [00:01<00:04, 62.52w/s, dev=1]model.vision.transformer.layers.11.post_attention_layernorm.bias:  21%|██▏       | 74/348 [00:01<00:04, 61.91w/s, dev=1]model.vision.transformer.layers.11.post_attention_layernorm.bias:  22%|██▏       | 75/348 [00:01<00:04, 62.72w/s, dev=1]model.vision.transformer.layers.11.post_attention_layernorm.weight:  22%|██▏       | 75/348 [00:01<00:04, 62.72w/s, dev=1]model.vision.transformer.layers.12.attention.dense.bias:  22%|██▏       | 76/348 [00:01<00:04, 63.54w/s, dev=1]           model.vision.transformer.layers.12.attention.dense.weight:  22%|██▏       | 77/348 [00:01<00:04, 64.37w/s, dev=1]model.vision.transformer.layers.12.attention.query_key_value.bias:  22%|██▏       | 78/348 [00:01<00:04, 65.06w/s, dev=1]model.vision.transformer.layers.12.attention.query_key_value.weight:  23%|██▎       | 79/348 [00:01<00:04, 65.88w/s, dev=1]model.vision.transformer.layers.12.input_layernorm.bias:  23%|██▎       | 80/348 [00:01<00:04, 66.22w/s, dev=1]            model.vision.transformer.layers.12.input_layernorm.weight:  23%|██▎       | 81/348 [00:01<00:03, 67.03w/s, dev=1]model.vision.transformer.layers.12.mlp.fc1.bias:  24%|██▎       | 82/348 [00:01<00:03, 67.85w/s, dev=1]          model.vision.transformer.layers.12.mlp.fc1.weight:  24%|██▍       | 83/348 [00:01<00:03, 68.67w/s, dev=1]model.vision.transformer.layers.12.mlp.fc2.bias:  24%|██▍       | 84/348 [00:01<00:03, 67.94w/s, dev=1]  model.vision.transformer.layers.12.mlp.fc2.weight:  24%|██▍       | 85/348 [00:01<00:03, 68.72w/s, dev=1]model.vision.transformer.layers.12.post_attention_layernorm.bias:  25%|██▍       | 86/348 [00:01<00:03, 67.78w/s, dev=1]model.vision.transformer.layers.12.post_attention_layernorm.weight:  25%|██▌       | 87/348 [00:01<00:03, 68.54w/s, dev=1]model.vision.transformer.layers.13.attention.dense.bias:  25%|██▌       | 88/348 [00:01<00:03, 69.32w/s, dev=1]           model.vision.transformer.layers.13.attention.dense.weight:  26%|██▌       | 89/348 [00:01<00:03, 70.10w/s, dev=1]model.vision.transformer.layers.13.attention.query_key_value.bias:  26%|██▌       | 90/348 [00:01<00:03, 70.69w/s, dev=1]model.vision.transformer.layers.13.attention.query_key_value.weight:  26%|██▌       | 91/348 [00:01<00:03, 71.46w/s, dev=1]model.vision.transformer.layers.13.input_layernorm.bias:  26%|██▋       | 92/348 [00:01<00:03, 71.67w/s, dev=1]            model.vision.transformer.layers.13.input_layernorm.weight:  27%|██▋       | 93/348 [00:01<00:03, 72.43w/s, dev=1]model.vision.transformer.layers.13.mlp.fc1.bias:  27%|██▋       | 94/348 [00:01<00:03, 73.20w/s, dev=1]          model.vision.transformer.layers.13.mlp.fc1.weight:  27%|██▋       | 95/348 [00:01<00:03, 73.97w/s, dev=1]model.vision.transformer.layers.13.mlp.fc2.bias:  28%|██▊       | 96/348 [00:01<00:03, 73.17w/s, dev=1]  model.vision.transformer.layers.13.mlp.fc2.weight:  28%|██▊       | 97/348 [00:01<00:03, 73.91w/s, dev=1]model.vision.transformer.layers.13.post_attention_layernorm.bias:  28%|██▊       | 98/348 [00:01<00:03, 73.14w/s, dev=1]model.vision.transformer.layers.13.post_attention_layernorm.weight:  28%|██▊       | 99/348 [00:01<00:03, 73.86w/s, dev=1]model.vision.transformer.layers.14.attention.dense.bias:  29%|██▊       | 100/348 [00:01<00:03, 74.60w/s, dev=1]          model.vision.transformer.layers.14.attention.dense.weight:  29%|██▉       | 101/348 [00:01<00:03, 75.34w/s, dev=1]model.vision.transformer.layers.14.attention.dense.weight:  29%|██▉       | 102/348 [00:01<00:03, 75.80w/s, dev=1]model.vision.transformer.layers.14.attention.query_key_value.bias:  29%|██▉       | 102/348 [00:01<00:03, 75.80w/s, dev=1]model.vision.transformer.layers.14.attention.query_key_value.weight:  30%|██▉       | 103/348 [00:01<00:03, 76.53w/s, dev=1]model.vision.transformer.layers.14.input_layernorm.bias:  30%|██▉       | 104/348 [00:01<00:03, 76.47w/s, dev=1]            model.vision.transformer.layers.14.input_layernorm.weight:  30%|███       | 105/348 [00:01<00:03, 77.19w/s, dev=1]model.vision.transformer.layers.14.mlp.fc1.bias:  30%|███       | 106/348 [00:01<00:03, 77.92w/s, dev=1]          model.vision.transformer.layers.14.mlp.fc1.weight:  31%|███       | 107/348 [00:01<00:03, 78.64w/s, dev=1]model.vision.transformer.layers.14.mlp.fc2.bias:  31%|███       | 108/348 [00:01<00:03, 77.99w/s, dev=1]  model.vision.transformer.layers.14.mlp.fc2.weight:  31%|███▏      | 109/348 [00:01<00:03, 78.69w/s, dev=1]model.vision.transformer.layers.14.post_attention_layernorm.bias:  32%|███▏      | 110/348 [00:01<00:03, 77.89w/s, dev=1]model.vision.transformer.layers.14.post_attention_layernorm.weight:  32%|███▏      | 111/348 [00:01<00:03, 78.57w/s, dev=1]model.vision.transformer.layers.15.attention.dense.bias:  32%|███▏      | 112/348 [00:01<00:02, 79.27w/s, dev=1]           model.vision.transformer.layers.15.attention.dense.weight:  32%|███▏      | 113/348 [00:01<00:02, 79.97w/s, dev=1]model.vision.transformer.layers.15.attention.query_key_value.bias:  33%|███▎      | 114/348 [00:01<00:02, 80.51w/s, dev=1]model.vision.transformer.layers.15.attention.query_key_value.weight:  33%|███▎      | 115/348 [00:01<00:02, 81.20w/s, dev=1]model.vision.transformer.layers.15.input_layernorm.bias:  33%|███▎      | 116/348 [00:01<00:02, 81.47w/s, dev=1]            model.vision.transformer.layers.15.input_layernorm.weight:  34%|███▎      | 117/348 [00:01<00:02, 82.16w/s, dev=1]model.vision.transformer.layers.15.mlp.fc1.bias:  34%|███▍      | 118/348 [00:01<00:02, 82.86w/s, dev=1]          model.vision.transformer.layers.15.mlp.fc1.weight:  34%|███▍      | 119/348 [00:01<00:02, 83.55w/s, dev=1]model.vision.transformer.layers.15.mlp.fc2.bias:  34%|███▍      | 120/348 [00:01<00:02, 82.29w/s, dev=1]  model.vision.transformer.layers.15.mlp.fc2.weight:  35%|███▍      | 121/348 [00:01<00:02, 82.95w/s, dev=1]model.vision.transformer.layers.15.post_attention_layernorm.bias:  35%|███▌      | 122/348 [00:01<00:02, 81.83w/s, dev=1]model.vision.transformer.layers.15.post_attention_layernorm.weight:  35%|███▌      | 123/348 [00:01<00:02, 82.47w/s, dev=1]model.vision.transformer.layers.16.attention.dense.bias:  36%|███▌      | 124/348 [00:01<00:02, 83.13w/s, dev=1]           model.vision.transformer.layers.16.attention.dense.weight:  36%|███▌      | 125/348 [00:01<00:02, 83.79w/s, dev=1]model.vision.transformer.layers.16.attention.query_key_value.bias:  36%|███▌      | 126/348 [00:01<00:02, 84.28w/s, dev=1]model.vision.transformer.layers.16.attention.query_key_value.weight:  36%|███▋      | 127/348 [00:01<00:02, 84.94w/s, dev=1]model.vision.transformer.layers.16.input_layernorm.bias:  37%|███▋      | 128/348 [00:01<00:02, 84.89w/s, dev=1]            model.vision.transformer.layers.16.input_layernorm.bias:  37%|███▋      | 129/348 [00:01<00:02, 85.54w/s, dev=1]model.vision.transformer.layers.16.input_layernorm.weight:  37%|███▋      | 129/348 [00:01<00:02, 85.53w/s, dev=1]model.vision.transformer.layers.16.mlp.fc1.bias:  37%|███▋      | 130/348 [00:01<00:02, 86.19w/s, dev=1]          model.vision.transformer.layers.16.mlp.fc1.weight:  38%|███▊      | 131/348 [00:01<00:02, 86.84w/s, dev=1]model.vision.transformer.layers.16.mlp.fc2.bias:  38%|███▊      | 132/348 [00:01<00:02, 85.74w/s, dev=1]  model.vision.transformer.layers.16.mlp.fc2.weight:  38%|███▊      | 133/348 [00:01<00:02, 86.36w/s, dev=1]model.vision.transformer.layers.16.post_attention_layernorm.bias:  39%|███▊      | 134/348 [00:01<00:02, 84.56w/s, dev=1]model.vision.transformer.layers.16.post_attention_layernorm.weight:  39%|███▉      | 135/348 [00:01<00:02, 85.17w/s, dev=1]model.vision.transformer.layers.17.attention.dense.bias:  39%|███▉      | 136/348 [00:01<00:02, 85.79w/s, dev=1]           model.vision.transformer.layers.17.attention.dense.weight:  39%|███▉      | 137/348 [00:01<00:02, 86.41w/s, dev=1]model.vision.transformer.layers.17.attention.query_key_value.bias:  40%|███▉      | 138/348 [00:01<00:02, 86.89w/s, dev=1]model.vision.transformer.layers.17.attention.query_key_value.weight:  40%|███▉      | 139/348 [00:01<00:02, 87.51w/s, dev=1]model.vision.transformer.layers.17.input_layernorm.bias:  40%|████      | 140/348 [00:01<00:02, 87.29w/s, dev=1]            model.vision.transformer.layers.17.input_layernorm.weight:  41%|████      | 141/348 [00:01<00:02, 87.89w/s, dev=1]model.vision.transformer.layers.17.mlp.fc1.bias:  41%|████      | 142/348 [00:01<00:02, 88.50w/s, dev=1]          model.vision.transformer.layers.17.mlp.fc1.weight:  41%|████      | 143/348 [00:01<00:02, 89.12w/s, dev=1]model.vision.transformer.layers.17.mlp.fc2.bias:  41%|████▏     | 144/348 [00:01<00:02, 88.28w/s, dev=1]  model.vision.transformer.layers.17.mlp.fc2.weight:  42%|████▏     | 145/348 [00:01<00:02, 88.87w/s, dev=1]model.vision.transformer.layers.17.post_attention_layernorm.bias:  42%|████▏     | 146/348 [00:01<00:02, 87.58w/s, dev=1]model.vision.transformer.layers.17.post_attention_layernorm.weight:  42%|████▏     | 147/348 [00:01<00:02, 88.16w/s, dev=1]model.vision.transformer.layers.18.attention.dense.bias:  43%|████▎     | 148/348 [00:01<00:02, 88.75w/s, dev=1]           model.vision.transformer.layers.18.attention.dense.weight:  43%|████▎     | 149/348 [00:01<00:02, 89.34w/s, dev=1]model.vision.transformer.layers.18.attention.query_key_value.bias:  43%|████▎     | 150/348 [00:01<00:02, 89.79w/s, dev=1]model.vision.transformer.layers.18.attention.query_key_value.weight:  43%|████▎     | 151/348 [00:01<00:02, 90.38w/s, dev=1]model.vision.transformer.layers.18.input_layernorm.bias:  44%|████▎     | 152/348 [00:01<00:02, 90.54w/s, dev=1]            model.vision.transformer.layers.18.input_layernorm.weight:  44%|████▍     | 153/348 [00:01<00:02, 91.12w/s, dev=1]model.vision.transformer.layers.18.mlp.fc1.bias:  44%|████▍     | 154/348 [00:01<00:02, 91.71w/s, dev=1]          model.vision.transformer.layers.18.mlp.fc1.weight:  45%|████▍     | 155/348 [00:01<00:02, 92.30w/s, dev=1]model.vision.transformer.layers.18.mlp.fc1.weight:  45%|████▍     | 156/348 [00:01<00:02, 90.55w/s, dev=1]model.vision.transformer.layers.18.mlp.fc2.bias:  45%|████▍     | 156/348 [00:01<00:02, 90.54w/s, dev=1]  model.vision.transformer.layers.18.mlp.fc2.weight:  45%|████▌     | 157/348 [00:01<00:02, 91.11w/s, dev=1]model.vision.transformer.layers.18.post_attention_layernorm.bias:  45%|████▌     | 158/348 [00:01<00:02, 89.98w/s, dev=1]model.vision.transformer.layers.18.post_attention_layernorm.weight:  46%|████▌     | 159/348 [00:01<00:02, 90.53w/s, dev=1]model.vision.transformer.layers.19.attention.dense.bias:  46%|████▌     | 160/348 [00:01<00:02, 91.09w/s, dev=1]           model.vision.transformer.layers.19.attention.dense.weight:  46%|████▋     | 161/348 [00:01<00:02, 91.65w/s, dev=1]model.vision.transformer.layers.19.attention.query_key_value.bias:  47%|████▋     | 162/348 [00:01<00:02, 92.06w/s, dev=1]model.vision.transformer.layers.19.attention.query_key_value.weight:  47%|████▋     | 163/348 [00:01<00:01, 92.62w/s, dev=1]model.vision.transformer.layers.19.input_layernorm.bias:  47%|████▋     | 164/348 [00:01<00:01, 92.50w/s, dev=1]            model.vision.transformer.layers.19.input_layernorm.weight:  47%|████▋     | 165/348 [00:01<00:01, 93.04w/s, dev=1]model.vision.transformer.layers.19.mlp.fc1.bias:  48%|████▊     | 166/348 [00:01<00:01, 93.60w/s, dev=1]          model.vision.transformer.layers.19.mlp.fc1.weight:  48%|████▊     | 167/348 [00:01<00:01, 94.15w/s, dev=1]model.vision.transformer.layers.19.mlp.fc2.bias:  48%|████▊     | 168/348 [00:01<00:01, 92.96w/s, dev=1]  model.vision.transformer.layers.19.mlp.fc2.weight:  49%|████▊     | 169/348 [00:01<00:01, 93.49w/s, dev=1]model.vision.transformer.layers.19.post_attention_layernorm.bias:  49%|████▉     | 170/348 [00:01<00:01, 92.57w/s, dev=1]model.vision.transformer.layers.19.post_attention_layernorm.weight:  49%|████▉     | 171/348 [00:01<00:01, 93.09w/s, dev=1]model.vision.transformer.layers.2.attention.dense.bias:  49%|████▉     | 172/348 [00:01<00:01, 93.63w/s, dev=1]            model.vision.transformer.layers.2.attention.dense.weight:  50%|████▉     | 173/348 [00:01<00:01, 94.16w/s, dev=1]model.vision.transformer.layers.2.attention.query_key_value.bias:  50%|█████     | 174/348 [00:01<00:01, 94.55w/s, dev=1]model.vision.transformer.layers.2.attention.query_key_value.weight:  50%|█████     | 175/348 [00:01<00:01, 95.09w/s, dev=1]model.vision.transformer.layers.2.input_layernorm.bias:  51%|█████     | 176/348 [00:01<00:01, 94.95w/s, dev=1]            model.vision.transformer.layers.2.input_layernorm.weight:  51%|█████     | 177/348 [00:01<00:01, 95.47w/s, dev=1]model.vision.transformer.layers.2.mlp.fc1.bias:  51%|█████     | 178/348 [00:01<00:01, 95.99w/s, dev=1]          model.vision.transformer.layers.2.mlp.fc1.weight:  51%|█████▏    | 179/348 [00:01<00:01, 96.52w/s, dev=1]model.vision.transformer.layers.2.mlp.fc2.bias:  52%|█████▏    | 180/348 [00:01<00:01, 95.54w/s, dev=1]  model.vision.transformer.layers.2.mlp.fc2.weight:  52%|█████▏    | 181/348 [00:01<00:01, 96.05w/s, dev=1]model.vision.transformer.layers.2.post_attention_layernorm.bias:  52%|█████▏    | 182/348 [00:02<00:01, 89.70w/s, dev=1]model.vision.transformer.layers.2.post_attention_layernorm.bias:  53%|█████▎    | 183/348 [00:02<00:01, 90.17w/s, dev=1]model.vision.transformer.layers.2.post_attention_layernorm.weight:  53%|█████▎    | 183/348 [00:02<00:01, 90.16w/s, dev=1]model.vision.transformer.layers.20.attention.dense.bias:  53%|█████▎    | 184/348 [00:02<00:01, 90.65w/s, dev=1]          model.vision.transformer.layers.20.attention.dense.weight:  53%|█████▎    | 185/348 [00:02<00:01, 91.13w/s, dev=1]model.vision.transformer.layers.20.attention.query_key_value.bias:  53%|█████▎    | 186/348 [00:02<00:01, 91.49w/s, dev=1]model.vision.transformer.layers.20.attention.query_key_value.weight:  54%|█████▎    | 187/348 [00:02<00:01, 91.97w/s, dev=1]model.vision.transformer.layers.20.input_layernorm.bias:  54%|█████▍    | 188/348 [00:02<00:01, 92.06w/s, dev=1]            model.vision.transformer.layers.20.input_layernorm.weight:  54%|█████▍    | 189/348 [00:02<00:01, 92.54w/s, dev=1]model.vision.transformer.layers.20.mlp.fc1.bias:  55%|█████▍    | 190/348 [00:02<00:01, 93.02w/s, dev=1]          model.vision.transformer.layers.20.mlp.fc1.weight:  55%|█████▍    | 191/348 [00:02<00:01, 93.51w/s, dev=1]model.vision.transformer.layers.20.mlp.fc2.bias:  55%|█████▌    | 192/348 [00:02<00:01, 92.96w/s, dev=1]  model.vision.transformer.layers.20.mlp.fc2.weight:  55%|█████▌    | 193/348 [00:02<00:01, 93.43w/s, dev=1]model.vision.transformer.layers.20.post_attention_layernorm.bias:  56%|█████▌    | 194/348 [00:02<00:01, 92.90w/s, dev=1]model.vision.transformer.layers.20.post_attention_layernorm.weight:  56%|█████▌    | 195/348 [00:02<00:01, 93.36w/s, dev=1]model.vision.transformer.layers.21.attention.dense.bias:  56%|█████▋    | 196/348 [00:02<00:01, 93.83w/s, dev=1]           model.vision.transformer.layers.21.attention.dense.weight:  57%|█████▋    | 197/348 [00:02<00:01, 94.31w/s, dev=1]model.vision.transformer.layers.21.attention.query_key_value.bias:  57%|█████▋    | 198/348 [00:02<00:01, 94.64w/s, dev=1]model.vision.transformer.layers.21.attention.query_key_value.weight:  57%|█████▋    | 199/348 [00:02<00:01, 95.11w/s, dev=1]model.vision.transformer.layers.21.input_layernorm.bias:  57%|█████▋    | 200/348 [00:02<00:01, 95.21w/s, dev=1]            model.vision.transformer.layers.21.input_layernorm.weight:  58%|█████▊    | 201/348 [00:02<00:01, 95.67w/s, dev=1]model.vision.transformer.layers.21.mlp.fc1.bias:  58%|█████▊    | 202/348 [00:02<00:01, 96.14w/s, dev=1]          model.vision.transformer.layers.21.mlp.fc1.weight:  58%|█████▊    | 203/348 [00:02<00:01, 96.61w/s, dev=1]model.vision.transformer.layers.21.mlp.fc2.bias:  59%|█████▊    | 204/348 [00:02<00:01, 96.07w/s, dev=1]  model.vision.transformer.layers.21.mlp.fc2.weight:  59%|█████▉    | 205/348 [00:02<00:01, 96.52w/s, dev=1]model.vision.transformer.layers.21.post_attention_layernorm.bias:  59%|█████▉    | 206/348 [00:02<00:01, 95.54w/s, dev=1]model.vision.transformer.layers.21.post_attention_layernorm.weight:  59%|█████▉    | 207/348 [00:02<00:01, 95.99w/s, dev=1]model.vision.transformer.layers.22.attention.dense.bias:  60%|█████▉    | 208/348 [00:02<00:01, 96.44w/s, dev=1]           model.vision.transformer.layers.22.attention.dense.weight:  60%|██████    | 209/348 [00:02<00:01, 96.90w/s, dev=1]model.vision.transformer.layers.22.attention.dense.weight:  60%|██████    | 210/348 [00:02<00:01, 97.23w/s, dev=1]model.vision.transformer.layers.22.attention.query_key_value.bias:  60%|██████    | 210/348 [00:02<00:01, 97.22w/s, dev=1]model.vision.transformer.layers.22.attention.query_key_value.weight:  61%|██████    | 211/348 [00:02<00:01, 97.68w/s, dev=1]model.vision.transformer.layers.22.input_layernorm.bias:  61%|██████    | 212/348 [00:02<00:01, 97.78w/s, dev=1]            model.vision.transformer.layers.22.input_layernorm.weight:  61%|██████    | 213/348 [00:02<00:01, 98.23w/s, dev=1]model.vision.transformer.layers.22.mlp.fc1.bias:  61%|██████▏   | 214/348 [00:02<00:01, 98.69w/s, dev=1]          model.vision.transformer.layers.22.mlp.fc1.weight:  62%|██████▏   | 215/348 [00:02<00:01, 99.14w/s, dev=1]model.vision.transformer.layers.22.mlp.fc2.bias:  62%|██████▏   | 216/348 [00:02<00:01, 95.58w/s, dev=1]  model.vision.transformer.layers.22.mlp.fc2.weight:  62%|██████▏   | 217/348 [00:02<00:01, 96.00w/s, dev=1]model.vision.transformer.layers.22.post_attention_layernorm.bias:  63%|██████▎   | 218/348 [00:02<00:01, 95.46w/s, dev=1]model.vision.transformer.layers.22.post_attention_layernorm.weight:  63%|██████▎   | 219/348 [00:02<00:01, 95.88w/s, dev=1]model.vision.transformer.layers.23.attention.dense.bias:  63%|██████▎   | 220/348 [00:02<00:01, 96.31w/s, dev=1]           model.vision.transformer.layers.23.attention.dense.weight:  64%|██████▎   | 221/348 [00:02<00:01, 96.75w/s, dev=1]model.vision.transformer.layers.23.attention.query_key_value.bias:  64%|██████▍   | 222/348 [00:02<00:01, 97.06w/s, dev=1]model.vision.transformer.layers.23.attention.query_key_value.weight:  64%|██████▍   | 223/348 [00:02<00:01, 97.49w/s, dev=1]model.vision.transformer.layers.23.input_layernorm.bias:  64%|██████▍   | 224/348 [00:02<00:01, 97.57w/s, dev=1]            model.vision.transformer.layers.23.input_layernorm.weight:  65%|██████▍   | 225/348 [00:02<00:01, 98.00w/s, dev=1]model.vision.transformer.layers.23.mlp.fc1.bias:  65%|██████▍   | 226/348 [00:02<00:01, 98.43w/s, dev=1]          model.vision.transformer.layers.23.mlp.fc1.weight:  65%|██████▌   | 227/348 [00:02<00:01, 98.86w/s, dev=1]model.vision.transformer.layers.23.mlp.fc2.bias:  66%|██████▌   | 228/348 [00:02<00:01, 98.33w/s, dev=1]  model.vision.transformer.layers.23.mlp.fc2.weight:  66%|██████▌   | 229/348 [00:02<00:01, 98.75w/s, dev=1]model.vision.transformer.layers.23.post_attention_layernorm.bias:  66%|██████▌   | 230/348 [00:02<00:01, 98.26w/s, dev=1]model.vision.transformer.layers.23.post_attention_layernorm.weight:  66%|██████▋   | 231/348 [00:02<00:01, 98.67w/s, dev=1]model.vision.transformer.layers.24.attention.dense.bias:  67%|██████▋   | 232/348 [00:02<00:01, 99.09w/s, dev=1]           model.vision.transformer.layers.24.attention.dense.weight:  67%|██████▋   | 233/348 [00:02<00:01, 99.51w/s, dev=1]model.vision.transformer.layers.24.attention.query_key_value.bias:  67%|██████▋   | 234/348 [00:02<00:01, 99.80w/s, dev=1]model.vision.transformer.layers.24.attention.query_key_value.weight:  68%|██████▊   | 235/348 [00:02<00:01, 100.22w/s, dev=1]model.vision.transformer.layers.24.input_layernorm.bias:  68%|██████▊   | 236/348 [00:02<00:01, 99.93w/s, dev=1]             model.vision.transformer.layers.24.input_layernorm.bias:  68%|██████▊   | 237/348 [00:02<00:01, 100.34w/s, dev=1]model.vision.transformer.layers.24.input_layernorm.weight:  68%|██████▊   | 237/348 [00:02<00:01, 100.34w/s, dev=1]model.vision.transformer.layers.24.mlp.fc1.bias:  68%|██████▊   | 238/348 [00:02<00:01, 100.76w/s, dev=1]          model.vision.transformer.layers.24.mlp.fc1.weight:  69%|██████▊   | 239/348 [00:02<00:01, 101.17w/s, dev=1]model.vision.transformer.layers.24.mlp.fc2.bias:  69%|██████▉   | 240/348 [00:02<00:01, 100.25w/s, dev=1]  model.vision.transformer.layers.24.mlp.fc2.weight:  69%|██████▉   | 241/348 [00:02<00:01, 100.65w/s, dev=1]model.vision.transformer.layers.24.post_attention_layernorm.bias:  70%|██████▉   | 242/348 [00:02<00:01, 99.85w/s, dev=1]model.vision.transformer.layers.24.post_attention_layernorm.weight:  70%|██████▉   | 243/348 [00:02<00:01, 100.24w/s, dev=1]model.vision.transformer.layers.25.attention.dense.bias:  70%|███████   | 244/348 [00:02<00:01, 100.65w/s, dev=1]           model.vision.transformer.layers.25.attention.dense.weight:  70%|███████   | 245/348 [00:02<00:01, 101.05w/s, dev=1]model.vision.transformer.layers.25.attention.query_key_value.bias:  71%|███████   | 246/348 [00:02<00:01, 101.34w/s, dev=1]model.vision.transformer.layers.25.attention.query_key_value.weight:  71%|███████   | 247/348 [00:02<00:00, 101.75w/s, dev=1]model.vision.transformer.layers.25.input_layernorm.bias:  71%|███████▏  | 248/348 [00:02<00:00, 101.63w/s, dev=1]            model.vision.transformer.layers.25.input_layernorm.weight:  72%|███████▏  | 249/348 [00:02<00:00, 102.02w/s, dev=1]model.vision.transformer.layers.25.mlp.fc1.bias:  72%|███████▏  | 250/348 [00:02<00:00, 102.42w/s, dev=1]          model.vision.transformer.layers.25.mlp.fc1.weight:  72%|███████▏  | 251/348 [00:02<00:00, 102.83w/s, dev=1]model.vision.transformer.layers.25.mlp.fc2.bias:  72%|███████▏  | 252/348 [00:02<00:00, 102.15w/s, dev=1]  model.vision.transformer.layers.25.mlp.fc2.weight:  73%|███████▎  | 253/348 [00:02<00:00, 102.54w/s, dev=1]model.vision.transformer.layers.25.post_attention_layernorm.bias:  73%|███████▎  | 254/348 [00:02<00:00, 101.65w/s, dev=1]model.vision.transformer.layers.25.post_attention_layernorm.weight:  73%|███████▎  | 255/348 [00:02<00:00, 102.03w/s, dev=1]model.vision.transformer.layers.26.attention.dense.bias:  74%|███████▎  | 256/348 [00:02<00:00, 102.43w/s, dev=1]           model.vision.transformer.layers.26.attention.dense.weight:  74%|███████▍  | 257/348 [00:02<00:00, 102.82w/s, dev=1]model.vision.transformer.layers.26.attention.query_key_value.bias:  74%|███████▍  | 258/348 [00:02<00:00, 102.96w/s, dev=1]model.vision.transformer.layers.26.attention.query_key_value.weight:  74%|███████▍  | 259/348 [00:02<00:00, 103.35w/s, dev=1]model.vision.transformer.layers.26.input_layernorm.bias:  75%|███████▍  | 260/348 [00:02<00:00, 103.32w/s, dev=1]            model.vision.transformer.layers.26.input_layernorm.weight:  75%|███████▌  | 261/348 [00:02<00:00, 103.70w/s, dev=1]model.vision.transformer.layers.26.mlp.fc1.bias:  75%|███████▌  | 262/348 [00:02<00:00, 104.09w/s, dev=1]          model.vision.transformer.layers.26.mlp.fc1.weight:  76%|███████▌  | 263/348 [00:02<00:00, 104.48w/s, dev=1]model.vision.transformer.layers.26.mlp.fc1.weight:  76%|███████▌  | 264/348 [00:02<00:00, 103.57w/s, dev=1]model.vision.transformer.layers.3.attention.dense.bias:  76%|███████▌  | 264/348 [00:02<00:00, 103.56w/s, dev=1]model.vision.transformer.layers.3.attention.dense.weight:  76%|███████▌  | 265/348 [00:02<00:00, 103.94w/s, dev=1]model.vision.transformer.layers.3.attention.query_key_value.bias:  76%|███████▋  | 266/348 [00:02<00:00, 104.20w/s, dev=1]model.vision.transformer.layers.3.attention.query_key_value.weight:  77%|███████▋  | 267/348 [00:02<00:00, 104.59w/s, dev=1]model.vision.transformer.layers.3.input_layernorm.bias:  77%|███████▋  | 268/348 [00:02<00:00, 104.48w/s, dev=1]            model.vision.transformer.layers.3.input_layernorm.weight:  77%|███████▋  | 269/348 [00:02<00:00, 104.86w/s, dev=1]model.vision.transformer.layers.3.mlp.fc1.bias:  78%|███████▊  | 270/348 [00:02<00:00, 105.24w/s, dev=1]          model.vision.transformer.layers.3.mlp.fc1.weight:  78%|███████▊  | 271/348 [00:02<00:00, 105.62w/s, dev=1]model.vision.transformer.layers.3.mlp.fc2.bias:  78%|███████▊  | 272/348 [00:02<00:00, 104.56w/s, dev=1]  model.vision.transformer.layers.3.mlp.fc2.weight:  78%|███████▊  | 273/348 [00:02<00:00, 104.93w/s, dev=1]model.vision.transformer.layers.3.post_attention_layernorm.bias:  79%|███████▊  | 274/348 [00:02<00:00, 103.98w/s, dev=1]model.vision.transformer.layers.3.post_attention_layernorm.weight:  79%|███████▉  | 275/348 [00:02<00:00, 104.34w/s, dev=1]model.vision.transformer.layers.4.attention.dense.bias:  79%|███████▉  | 276/348 [00:02<00:00, 104.71w/s, dev=1]           model.vision.transformer.layers.4.attention.dense.weight:  80%|███████▉  | 277/348 [00:02<00:00, 105.08w/s, dev=1]model.vision.transformer.layers.4.attention.query_key_value.bias:  80%|███████▉  | 278/348 [00:02<00:00, 105.35w/s, dev=1]model.vision.transformer.layers.4.attention.query_key_value.weight:  80%|████████  | 279/348 [00:02<00:00, 105.72w/s, dev=1]model.vision.transformer.layers.4.input_layernorm.bias:  80%|████████  | 280/348 [00:02<00:00, 105.69w/s, dev=1]            model.vision.transformer.layers.4.input_layernorm.weight:  81%|████████  | 281/348 [00:02<00:00, 106.05w/s, dev=1]model.vision.transformer.layers.4.mlp.fc1.bias:  81%|████████  | 282/348 [00:02<00:00, 106.42w/s, dev=1]          model.vision.transformer.layers.4.mlp.fc1.weight:  81%|████████▏ | 283/348 [00:02<00:00, 106.80w/s, dev=1]model.vision.transformer.layers.4.mlp.fc2.bias:  82%|████████▏ | 284/348 [00:02<00:00, 105.64w/s, dev=1]  model.vision.transformer.layers.4.mlp.fc2.weight:  82%|████████▏ | 285/348 [00:02<00:00, 106.00w/s, dev=1]model.vision.transformer.layers.4.post_attention_layernorm.bias:  82%|████████▏ | 286/348 [00:02<00:00, 105.25w/s, dev=1]model.vision.transformer.layers.4.post_attention_layernorm.weight:  82%|████████▏ | 287/348 [00:02<00:00, 105.60w/s, dev=1]model.vision.transformer.layers.5.attention.dense.bias:  83%|████████▎ | 288/348 [00:02<00:00, 105.96w/s, dev=1]           model.vision.transformer.layers.5.attention.dense.weight:  83%|████████▎ | 289/348 [00:02<00:00, 106.33w/s, dev=1]model.vision.transformer.layers.5.attention.query_key_value.bias:  83%|████████▎ | 290/348 [00:02<00:00, 106.59w/s, dev=1]model.vision.transformer.layers.5.attention.query_key_value.bias:  84%|████████▎ | 291/348 [00:02<00:00, 106.95w/s, dev=1]model.vision.transformer.layers.5.attention.query_key_value.weight:  84%|████████▎ | 291/348 [00:02<00:00, 106.95w/s, dev=1]model.vision.transformer.layers.5.input_layernorm.bias:  84%|████████▍ | 292/348 [00:02<00:00, 106.74w/s, dev=1]            model.vision.transformer.layers.5.input_layernorm.weight:  84%|████████▍ | 293/348 [00:02<00:00, 107.09w/s, dev=1]model.vision.transformer.layers.5.mlp.fc1.bias:  84%|████████▍ | 294/348 [00:02<00:00, 107.45w/s, dev=1]          model.vision.transformer.layers.5.mlp.fc1.weight:  85%|████████▍ | 295/348 [00:02<00:00, 107.81w/s, dev=1]model.vision.transformer.layers.5.mlp.fc2.bias:  85%|████████▌ | 296/348 [00:02<00:00, 107.10w/s, dev=1]  model.vision.transformer.layers.5.mlp.fc2.weight:  85%|████████▌ | 297/348 [00:02<00:00, 107.44w/s, dev=1]model.vision.transformer.layers.5.post_attention_layernorm.bias:  86%|████████▌ | 298/348 [00:02<00:00, 106.72w/s, dev=1]model.vision.transformer.layers.5.post_attention_layernorm.weight:  86%|████████▌ | 299/348 [00:02<00:00, 107.06w/s, dev=1]model.vision.transformer.layers.6.attention.dense.bias:  86%|████████▌ | 300/348 [00:02<00:00, 107.42w/s, dev=1]           model.vision.transformer.layers.6.attention.dense.weight:  86%|████████▋ | 301/348 [00:02<00:00, 107.77w/s, dev=1]model.vision.transformer.layers.6.attention.query_key_value.bias:  87%|████████▋ | 302/348 [00:02<00:00, 108.01w/s, dev=1]model.vision.transformer.layers.6.attention.query_key_value.weight:  87%|████████▋ | 303/348 [00:02<00:00, 108.36w/s, dev=1]model.vision.transformer.layers.6.input_layernorm.bias:  87%|████████▋ | 304/348 [00:02<00:00, 108.29w/s, dev=1]            model.vision.transformer.layers.6.input_layernorm.weight:  88%|████████▊ | 305/348 [00:02<00:00, 108.63w/s, dev=1]model.vision.transformer.layers.6.mlp.fc1.bias:  88%|████████▊ | 306/348 [00:02<00:00, 108.98w/s, dev=1]          model.vision.transformer.layers.6.mlp.fc1.weight:  88%|████████▊ | 307/348 [00:02<00:00, 109.33w/s, dev=1]model.vision.transformer.layers.6.mlp.fc2.bias:  89%|████████▊ | 308/348 [00:02<00:00, 108.57w/s, dev=1]  model.vision.transformer.layers.6.mlp.fc2.weight:  89%|████████▉ | 309/348 [00:02<00:00, 108.91w/s, dev=1]model.vision.transformer.layers.6.post_attention_layernorm.bias:  89%|████████▉ | 310/348 [00:02<00:00, 108.10w/s, dev=1]model.vision.transformer.layers.6.post_attention_layernorm.weight:  89%|████████▉ | 311/348 [00:02<00:00, 108.44w/s, dev=1]model.vision.transformer.layers.7.attention.dense.bias:  90%|████████▉ | 312/348 [00:02<00:00, 108.78w/s, dev=1]           model.vision.transformer.layers.7.attention.dense.weight:  90%|████████▉ | 313/348 [00:02<00:00, 109.12w/s, dev=1]model.vision.transformer.layers.7.attention.query_key_value.bias:  90%|█████████ | 314/348 [00:02<00:00, 109.36w/s, dev=1]model.vision.transformer.layers.7.attention.query_key_value.weight:  91%|█████████ | 315/348 [00:02<00:00, 109.70w/s, dev=1]model.vision.transformer.layers.7.input_layernorm.bias:  91%|█████████ | 316/348 [00:02<00:00, 109.00w/s, dev=1]            model.vision.transformer.layers.7.input_layernorm.weight:  91%|█████████ | 317/348 [00:02<00:00, 109.33w/s, dev=1]model.vision.transformer.layers.7.input_layernorm.weight:  91%|█████████▏| 318/348 [00:02<00:00, 109.67w/s, dev=1]model.vision.transformer.layers.7.mlp.fc1.bias:  91%|█████████▏| 318/348 [00:02<00:00, 109.67w/s, dev=1]          model.vision.transformer.layers.7.mlp.fc1.weight:  92%|█████████▏| 319/348 [00:02<00:00, 110.00w/s, dev=1]model.vision.transformer.layers.7.mlp.fc2.bias:  92%|█████████▏| 320/348 [00:02<00:00, 109.32w/s, dev=1]  model.vision.transformer.layers.7.mlp.fc2.weight:  92%|█████████▏| 321/348 [00:02<00:00, 109.64w/s, dev=1]model.vision.transformer.layers.7.post_attention_layernorm.bias:  93%|█████████▎| 322/348 [00:03<00:00, 102.73w/s, dev=1]model.vision.transformer.layers.7.post_attention_layernorm.weight:  93%|█████████▎| 323/348 [00:03<00:00, 103.03w/s, dev=1]model.vision.transformer.layers.8.attention.dense.bias:  93%|█████████▎| 324/348 [00:03<00:00, 103.34w/s, dev=1]           model.vision.transformer.layers.8.attention.dense.weight:  93%|█████████▎| 325/348 [00:03<00:00, 103.64w/s, dev=1]model.vision.transformer.layers.8.attention.query_key_value.bias:  94%|█████████▎| 326/348 [00:03<00:00, 103.79w/s, dev=1]model.vision.transformer.layers.8.attention.query_key_value.weight:  94%|█████████▍| 327/348 [00:03<00:00, 104.10w/s, dev=1]model.vision.transformer.layers.8.input_layernorm.bias:  94%|█████████▍| 328/348 [00:03<00:00, 104.14w/s, dev=1]            model.vision.transformer.layers.8.input_layernorm.weight:  95%|█████████▍| 329/348 [00:03<00:00, 104.45w/s, dev=1]model.vision.transformer.layers.8.mlp.fc1.bias:  95%|█████████▍| 330/348 [00:03<00:00, 104.76w/s, dev=1]          model.vision.transformer.layers.8.mlp.fc1.weight:  95%|█████████▌| 331/348 [00:03<00:00, 105.07w/s, dev=1]model.vision.transformer.layers.8.mlp.fc2.bias:  95%|█████████▌| 332/348 [00:03<00:00, 104.67w/s, dev=1]  model.vision.transformer.layers.8.mlp.fc2.weight:  96%|█████████▌| 333/348 [00:03<00:00, 104.98w/s, dev=1]model.vision.transformer.layers.8.post_attention_layernorm.bias:  96%|█████████▌| 334/348 [00:03<00:00, 104.59w/s, dev=1]model.vision.transformer.layers.8.post_attention_layernorm.weight:  96%|█████████▋| 335/348 [00:03<00:00, 104.89w/s, dev=1]model.vision.transformer.layers.9.attention.dense.bias:  97%|█████████▋| 336/348 [00:03<00:00, 105.20w/s, dev=1]           model.vision.transformer.layers.9.attention.dense.weight:  97%|█████████▋| 337/348 [00:03<00:00, 105.51w/s, dev=1]model.vision.transformer.layers.9.attention.query_key_value.bias:  97%|█████████▋| 338/348 [00:03<00:00, 105.72w/s, dev=1]model.vision.transformer.layers.9.attention.query_key_value.weight:  97%|█████████▋| 339/348 [00:03<00:00, 106.02w/s, dev=1]model.vision.transformer.layers.9.input_layernorm.bias:  98%|█████████▊| 340/348 [00:03<00:00, 106.08w/s, dev=1]            model.vision.transformer.layers.9.input_layernorm.weight:  98%|█████████▊| 341/348 [00:03<00:00, 106.38w/s, dev=1]model.vision.transformer.layers.9.mlp.fc1.bias:  98%|█████████▊| 342/348 [00:03<00:00, 106.69w/s, dev=1]          model.vision.transformer.layers.9.mlp.fc1.weight:  99%|█████████▊| 343/348 [00:03<00:00, 107.00w/s, dev=1]model.vision.transformer.layers.9.mlp.fc2.bias:  99%|█████████▉| 344/348 [00:03<00:00, 106.59w/s, dev=1]  model.vision.transformer.layers.9.mlp.fc2.bias:  99%|█████████▉| 345/348 [00:03<00:00, 106.90w/s, dev=1]model.vision.transformer.layers.9.mlp.fc2.weight:  99%|█████████▉| 345/348 [00:03<00:00, 106.89w/s, dev=1]model.vision.transformer.layers.9.post_attention_layernorm.bias:  99%|█████████▉| 346/348 [00:03<00:00, 106.49w/s, dev=1]model.vision.transformer.layers.9.post_attention_layernorm.weight: 100%|█████████▉| 347/348 [00:03<00:00, 106.80w/s, dev=1]                                                                                                                             0%|          | 0/439 [00:00<?, ?w/s]model.vision.linear_proj.linear_proj.weight:   0%|          | 0/439 [00:00<?, ?w/s, dev=1]model.vision.linear_proj.linear_proj.weight:   0%|          | 1/439 [00:00<01:25,  5.13w/s, dev=1]model.vision.linear_proj.norm1.bias:   0%|          | 1/439 [00:00<01:25,  5.12w/s, dev=1]        model.vision.linear_proj.norm1.weight:   0%|          | 2/439 [00:00<00:42, 10.22w/s, dev=1]model.vision.transformer.layers.26.mlp.fc2.bias:   1%|          | 3/439 [00:00<00:28, 15.30w/s, dev=1]model.vision.transformer.layers.26.mlp.fc2.weight:   1%|          | 4/439 [00:00<00:21, 20.36w/s, dev=1]model.vision.transformer.layers.26.post_attention_layernorm.bias:   1%|          | 5/439 [00:00<00:23, 18.27w/s, dev=1]model.vision.transformer.layers.26.post_attention_layernorm.weight:   1%|▏         | 6/439 [00:00<00:19, 21.89w/s, dev=1]model.vision.transformer.layers.27.attention.dense.bias:   2%|▏         | 7/439 [00:00<00:16, 25.53w/s, dev=1]           model.vision.transformer.layers.27.attention.dense.weight:   2%|▏         | 8/439 [00:00<00:14, 29.16w/s, dev=1]model.vision.transformer.layers.27.attention.query_key_value.bias:   2%|▏         | 9/439 [00:00<00:13, 32.45w/s, dev=1]model.vision.transformer.layers.27.attention.query_key_value.weight:   2%|▏         | 10/439 [00:00<00:11, 36.03w/s, dev=1]model.vision.transformer.layers.27.input_layernorm.bias:   3%|▎         | 11/439 [00:00<00:11, 38.46w/s, dev=1]            model.vision.transformer.layers.27.input_layernorm.weight:   3%|▎         | 12/439 [00:00<00:10, 41.91w/s, dev=1]model.vision.transformer.layers.27.mlp.fc1.bias:   3%|▎         | 13/439 [00:00<00:09, 45.38w/s, dev=1]          model.vision.transformer.layers.27.mlp.fc1.weight:   3%|▎         | 14/439 [00:00<00:08, 48.84w/s, dev=1]model.vision.transformer.layers.27.mlp.fc1.weight:   3%|▎         | 15/439 [00:00<00:08, 48.49w/s, dev=1]model.vision.transformer.layers.27.mlp.fc2.bias:   3%|▎         | 15/439 [00:00<00:08, 48.46w/s, dev=1]  model.vision.transformer.layers.27.mlp.fc2.weight:   4%|▎         | 16/439 [00:00<00:08, 51.64w/s, dev=1]model.vision.transformer.layers.27.post_attention_layernorm.bias:   4%|▍         | 17/439 [00:00<00:08, 51.21w/s, dev=1]model.vision.transformer.layers.27.post_attention_layernorm.weight:   4%|▍         | 18/439 [00:00<00:07, 54.16w/s, dev=1]model.vision.transformer.layers.28.attention.dense.bias:   4%|▍         | 19/439 [00:00<00:07, 57.14w/s, dev=1]           model.vision.transformer.layers.28.attention.dense.weight:   5%|▍         | 20/439 [00:00<00:06, 60.12w/s, dev=1]model.vision.transformer.layers.28.attention.query_key_value.bias:   5%|▍         | 21/439 [00:00<00:06, 62.56w/s, dev=1]model.vision.transformer.layers.28.attention.query_key_value.weight:   5%|▌         | 22/439 [00:00<00:06, 65.49w/s, dev=1]model.vision.transformer.layers.28.input_layernorm.bias:   5%|▌         | 23/439 [00:00<00:06, 66.79w/s, dev=1]            model.vision.transformer.layers.28.input_layernorm.weight:   5%|▌         | 24/439 [00:00<00:05, 69.64w/s, dev=1]model.vision.transformer.layers.28.mlp.fc1.bias:   6%|▌         | 25/439 [00:00<00:05, 72.51w/s, dev=1]          model.vision.transformer.layers.28.mlp.fc1.weight:   6%|▌         | 26/439 [00:00<00:05, 75.38w/s, dev=1]model.vision.transformer.layers.28.mlp.fc2.bias:   6%|▌         | 27/439 [00:00<00:05, 73.52w/s, dev=1]  model.vision.transformer.layers.28.mlp.fc2.weight:   6%|▋         | 28/439 [00:00<00:05, 76.17w/s, dev=1]model.vision.transformer.layers.28.post_attention_layernorm.bias:   7%|▋         | 29/439 [00:00<00:05, 74.38w/s, dev=1]model.vision.transformer.layers.28.post_attention_layernorm.weight:   7%|▋         | 30/439 [00:00<00:05, 76.87w/s, dev=1]model.vision.transformer.layers.29.attention.dense.bias:   7%|▋         | 31/439 [00:00<00:05, 79.40w/s, dev=1]           model.vision.transformer.layers.29.attention.dense.weight:   7%|▋         | 32/439 [00:00<00:04, 81.93w/s, dev=1]model.vision.transformer.layers.29.attention.query_key_value.bias:   8%|▊         | 33/439 [00:00<00:04, 83.77w/s, dev=1]model.vision.transformer.layers.29.attention.query_key_value.weight:   8%|▊         | 34/439 [00:00<00:04, 86.27w/s, dev=1]model.vision.transformer.layers.29.input_layernorm.bias:   8%|▊         | 35/439 [00:00<00:04, 87.02w/s, dev=1]            model.vision.transformer.layers.29.input_layernorm.weight:   8%|▊         | 36/439 [00:00<00:04, 89.45w/s, dev=1]model.vision.transformer.layers.29.mlp.fc1.bias:   8%|▊         | 37/439 [00:00<00:04, 91.90w/s, dev=1]          model.vision.transformer.layers.29.mlp.fc1.weight:   9%|▊         | 38/439 [00:00<00:04, 94.34w/s, dev=1]model.vision.transformer.layers.29.mlp.fc1.weight:   9%|▉         | 39/439 [00:00<00:04, 91.80w/s, dev=1]model.vision.transformer.layers.29.mlp.fc2.bias:   9%|▉         | 39/439 [00:00<00:04, 91.76w/s, dev=1]  model.vision.transformer.layers.29.mlp.fc2.weight:   9%|▉         | 40/439 [00:00<00:04, 94.05w/s, dev=1]model.vision.transformer.layers.29.post_attention_layernorm.bias:   9%|▉         | 41/439 [00:00<00:04, 91.64w/s, dev=1]model.vision.transformer.layers.29.post_attention_layernorm.weight:  10%|▉         | 42/439 [00:00<00:04, 93.79w/s, dev=1]model.vision.transformer.layers.30.attention.dense.bias:  10%|▉         | 43/439 [00:00<00:04, 95.99w/s, dev=1]           model.vision.transformer.layers.30.attention.dense.weight:  10%|█         | 44/439 [00:00<00:04, 98.19w/s, dev=1]model.vision.transformer.layers.30.attention.query_key_value.bias:  10%|█         | 45/439 [00:00<00:03, 99.73w/s, dev=1]model.vision.transformer.layers.30.attention.query_key_value.weight:  10%|█         | 46/439 [00:00<00:03, 101.89w/s, dev=1]model.vision.transformer.layers.30.input_layernorm.bias:  11%|█         | 47/439 [00:00<00:03, 102.25w/s, dev=1]            model.vision.transformer.layers.30.input_layernorm.weight:  11%|█         | 48/439 [00:00<00:03, 104.36w/s, dev=1]model.vision.transformer.layers.30.mlp.fc1.bias:  11%|█         | 49/439 [00:00<00:03, 106.50w/s, dev=1]          model.vision.transformer.layers.30.mlp.fc1.weight:  11%|█▏        | 50/439 [00:00<00:03, 108.58w/s, dev=1]model.vision.transformer.layers.30.mlp.fc2.bias:  12%|█▏        | 51/439 [00:00<00:03, 105.72w/s, dev=1]  model.vision.transformer.layers.30.mlp.fc2.weight:  12%|█▏        | 52/439 [00:00<00:03, 107.71w/s, dev=1]model.vision.transformer.layers.30.post_attention_layernorm.bias:  12%|█▏        | 53/439 [00:00<00:03, 105.06w/s, dev=1]model.vision.transformer.layers.30.post_attention_layernorm.weight:  12%|█▏        | 54/439 [00:00<00:03, 106.96w/s, dev=1]model.vision.transformer.layers.31.attention.dense.bias:  13%|█▎        | 55/439 [00:00<00:03, 108.90w/s, dev=1]           model.vision.transformer.layers.31.attention.dense.weight:  13%|█▎        | 56/439 [00:00<00:03, 110.85w/s, dev=1]model.vision.transformer.layers.31.attention.query_key_value.bias:  13%|█▎        | 57/439 [00:00<00:03, 112.20w/s, dev=1]model.vision.transformer.layers.31.attention.query_key_value.weight:  13%|█▎        | 58/439 [00:00<00:03, 114.11w/s, dev=1]model.vision.transformer.layers.31.input_layernorm.bias:  13%|█▎        | 59/439 [00:00<00:03, 114.31w/s, dev=1]            model.vision.transformer.layers.31.input_layernorm.weight:  14%|█▎        | 60/439 [00:00<00:03, 116.18w/s, dev=1]model.vision.transformer.layers.31.mlp.fc1.bias:  14%|█▍        | 61/439 [00:00<00:03, 118.08w/s, dev=1]          model.vision.transformer.layers.31.mlp.fc1.weight:  14%|█▍        | 62/439 [00:00<00:03, 119.98w/s, dev=1]model.vision.transformer.layers.31.mlp.fc1.weight:  14%|█▍        | 63/439 [00:00<00:03, 115.22w/s, dev=1]model.vision.transformer.layers.31.mlp.fc2.bias:  14%|█▍        | 63/439 [00:00<00:03, 115.18w/s, dev=1]  model.vision.transformer.layers.31.mlp.fc2.weight:  15%|█▍        | 64/439 [00:00<00:03, 116.94w/s, dev=1]model.vision.transformer.layers.31.post_attention_layernorm.bias:  15%|█▍        | 65/439 [00:00<00:03, 114.34w/s, dev=1]model.vision.transformer.layers.31.post_attention_layernorm.weight:  15%|█▌        | 66/439 [00:00<00:03, 116.02w/s, dev=1]model.vision.transformer.layers.32.attention.dense.bias:  15%|█▌        | 67/439 [00:00<00:03, 117.74w/s, dev=1]           model.vision.transformer.layers.32.attention.dense.weight:  15%|█▌        | 68/439 [00:00<00:03, 119.47w/s, dev=1]model.vision.transformer.layers.32.attention.query_key_value.bias:  16%|█▌        | 69/439 [00:00<00:03, 120.55w/s, dev=1]model.vision.transformer.layers.32.attention.query_key_value.weight:  16%|█▌        | 70/439 [00:00<00:03, 122.24w/s, dev=1]model.vision.transformer.layers.32.input_layernorm.bias:  16%|█▌        | 71/439 [00:00<00:03, 121.36w/s, dev=1]            model.vision.transformer.layers.32.input_layernorm.weight:  16%|█▋        | 72/439 [00:00<00:02, 122.99w/s, dev=1]model.vision.transformer.layers.32.mlp.fc1.bias:  17%|█▋        | 73/439 [00:00<00:02, 124.66w/s, dev=1]          model.vision.transformer.layers.32.mlp.fc1.weight:  17%|█▋        | 74/439 [00:00<00:02, 126.34w/s, dev=1]model.vision.transformer.layers.32.mlp.fc2.bias:  17%|█▋        | 75/439 [00:00<00:02, 122.43w/s, dev=1]  model.vision.transformer.layers.32.mlp.fc2.weight:  17%|█▋        | 76/439 [00:00<00:02, 123.98w/s, dev=1]model.vision.transformer.layers.32.post_attention_layernorm.bias:  18%|█▊        | 77/439 [00:00<00:02, 120.71w/s, dev=1]model.vision.transformer.layers.32.post_attention_layernorm.weight:  18%|█▊        | 78/439 [00:00<00:02, 122.20w/s, dev=1]model.vision.transformer.layers.33.attention.dense.bias:  18%|█▊        | 79/439 [00:00<00:02, 123.73w/s, dev=1]           model.vision.transformer.layers.33.attention.dense.weight:  18%|█▊        | 80/439 [00:00<00:02, 125.27w/s, dev=1]model.vision.transformer.layers.33.attention.query_key_value.bias:  18%|█▊        | 81/439 [00:00<00:02, 126.00w/s, dev=1]model.vision.transformer.layers.33.attention.query_key_value.weight:  19%|█▊        | 82/439 [00:00<00:02, 127.50w/s, dev=1]model.vision.transformer.layers.33.input_layernorm.bias:  19%|█▉        | 83/439 [00:00<00:02, 126.58w/s, dev=1]            model.vision.transformer.layers.33.input_layernorm.weight:  19%|█▉        | 84/439 [00:00<00:02, 128.04w/s, dev=1]model.vision.transformer.layers.33.mlp.fc1.bias:  19%|█▉        | 85/439 [00:00<00:02, 129.53w/s, dev=1]          model.vision.transformer.layers.33.mlp.fc1.weight:  20%|█▉        | 86/439 [00:00<00:02, 131.02w/s, dev=1]model.vision.transformer.layers.33.mlp.fc1.weight:  20%|█▉        | 87/439 [00:00<00:02, 127.43w/s, dev=1]model.vision.transformer.layers.33.mlp.fc2.bias:  20%|█▉        | 87/439 [00:00<00:02, 127.39w/s, dev=1]  model.vision.transformer.layers.33.mlp.fc2.weight:  20%|██        | 88/439 [00:00<00:02, 128.80w/s, dev=1]model.vision.transformer.layers.33.post_attention_layernorm.bias:  20%|██        | 89/439 [00:00<00:02, 124.66w/s, dev=1]model.vision.transformer.layers.33.post_attention_layernorm.weight:  21%|██        | 90/439 [00:00<00:02, 125.98w/s, dev=1]model.vision.transformer.layers.34.attention.dense.bias:  21%|██        | 91/439 [00:00<00:02, 127.35w/s, dev=1]           model.vision.transformer.layers.34.attention.dense.weight:  21%|██        | 92/439 [00:00<00:02, 128.73w/s, dev=1]model.vision.transformer.layers.34.attention.query_key_value.bias:  21%|██        | 93/439 [00:00<00:02, 129.60w/s, dev=1]model.vision.transformer.layers.34.attention.query_key_value.weight:  21%|██▏       | 94/439 [00:00<00:02, 130.95w/s, dev=1]model.vision.transformer.layers.34.input_layernorm.bias:  22%|██▏       | 95/439 [00:00<00:02, 130.93w/s, dev=1]            model.vision.transformer.layers.34.input_layernorm.weight:  22%|██▏       | 96/439 [00:00<00:02, 132.27w/s, dev=1]model.vision.transformer.layers.34.mlp.fc1.bias:  22%|██▏       | 97/439 [00:00<00:02, 133.62w/s, dev=1]          model.vision.transformer.layers.34.mlp.fc1.weight:  22%|██▏       | 98/439 [00:00<00:02, 134.97w/s, dev=1]model.vision.transformer.layers.34.mlp.fc2.bias:  23%|██▎       | 99/439 [00:00<00:02, 131.60w/s, dev=1]  model.vision.transformer.layers.34.mlp.fc2.weight:  23%|██▎       | 100/439 [00:00<00:02, 132.86w/s, dev=1]model.vision.transformer.layers.34.post_attention_layernorm.bias:  23%|██▎       | 101/439 [00:00<00:02, 122.69w/s, dev=1]model.vision.transformer.layers.34.post_attention_layernorm.weight:  23%|██▎       | 102/439 [00:00<00:02, 123.84w/s, dev=1]model.vision.transformer.layers.35.attention.dense.bias:  23%|██▎       | 103/439 [00:00<00:02, 125.02w/s, dev=1]           model.vision.transformer.layers.35.attention.dense.weight:  24%|██▎       | 104/439 [00:00<00:02, 126.21w/s, dev=1]model.vision.transformer.layers.35.attention.query_key_value.bias:  24%|██▍       | 105/439 [00:00<00:03, 110.76w/s, dev=1]model.vision.transformer.layers.35.attention.query_key_value.weight:  24%|██▍       | 106/439 [00:00<00:02, 111.71w/s, dev=1]model.vision.transformer.layers.35.input_layernorm.bias:  24%|██▍       | 107/439 [00:00<00:02, 111.20w/s, dev=1]            model.vision.transformer.layers.35.input_layernorm.weight:  25%|██▍       | 108/439 [00:00<00:02, 112.19w/s, dev=1]model.vision.transformer.layers.35.mlp.fc1.bias:  25%|██▍       | 109/439 [00:00<00:02, 113.19w/s, dev=1]          model.vision.transformer.layers.35.mlp.fc1.weight:  25%|██▌       | 110/439 [00:00<00:02, 114.20w/s, dev=1]model.vision.transformer.layers.35.mlp.fc1.weight:  25%|██▌       | 111/439 [00:00<00:02, 112.50w/s, dev=1]model.vision.transformer.layers.35.mlp.fc2.bias:  25%|██▌       | 111/439 [00:00<00:02, 112.49w/s, dev=1]  model.vision.transformer.layers.35.mlp.fc2.weight:  26%|██▌       | 112/439 [00:00<00:02, 113.47w/s, dev=1]model.vision.transformer.layers.35.post_attention_layernorm.bias:  26%|██▌       | 113/439 [00:01<00:02, 111.95w/s, dev=1]model.vision.transformer.layers.35.post_attention_layernorm.weight:  26%|██▌       | 114/439 [00:01<00:02, 112.89w/s, dev=1]model.vision.transformer.layers.36.attention.dense.bias:  26%|██▌       | 115/439 [00:01<00:02, 113.86w/s, dev=1]           model.vision.transformer.layers.36.attention.dense.weight:  26%|██▋       | 116/439 [00:01<00:02, 114.84w/s, dev=1]model.vision.transformer.layers.36.attention.query_key_value.bias:  27%|██▋       | 117/439 [00:01<00:02, 115.49w/s, dev=1]model.vision.transformer.layers.36.attention.query_key_value.weight:  27%|██▋       | 118/439 [00:01<00:02, 116.45w/s, dev=1]model.vision.transformer.layers.36.input_layernorm.bias:  27%|██▋       | 119/439 [00:01<00:02, 116.41w/s, dev=1]            model.vision.transformer.layers.36.input_layernorm.weight:  27%|██▋       | 120/439 [00:01<00:02, 117.35w/s, dev=1]model.vision.transformer.layers.36.mlp.fc1.bias:  28%|██▊       | 121/439 [00:01<00:02, 118.31w/s, dev=1]          model.vision.transformer.layers.36.mlp.fc1.weight:  28%|██▊       | 122/439 [00:01<00:02, 119.27w/s, dev=1]model.vision.transformer.layers.36.mlp.fc2.bias:  28%|██▊       | 123/439 [00:01<00:02, 117.68w/s, dev=1]  model.vision.transformer.layers.36.mlp.fc2.weight:  28%|██▊       | 124/439 [00:01<00:02, 118.59w/s, dev=1]model.vision.transformer.layers.36.post_attention_layernorm.bias:  28%|██▊       | 125/439 [00:01<00:02, 117.07w/s, dev=1]model.vision.transformer.layers.36.post_attention_layernorm.weight:  29%|██▊       | 126/439 [00:01<00:02, 117.96w/s, dev=1]model.vision.transformer.layers.37.attention.dense.bias:  29%|██▉       | 127/439 [00:01<00:02, 118.88w/s, dev=1]           model.vision.transformer.layers.37.attention.dense.weight:  29%|██▉       | 128/439 [00:01<00:02, 119.80w/s, dev=1]model.vision.transformer.layers.37.attention.query_key_value.bias:  29%|██▉       | 129/439 [00:01<00:02, 120.39w/s, dev=1]model.vision.transformer.layers.37.attention.query_key_value.weight:  30%|██▉       | 130/439 [00:01<00:02, 121.30w/s, dev=1]model.vision.transformer.layers.37.input_layernorm.bias:  30%|██▉       | 131/439 [00:01<00:02, 121.30w/s, dev=1]            model.vision.transformer.layers.37.input_layernorm.weight:  30%|███       | 132/439 [00:01<00:02, 122.20w/s, dev=1]model.vision.transformer.layers.37.mlp.fc1.bias:  30%|███       | 133/439 [00:01<00:02, 123.11w/s, dev=1]          model.vision.transformer.layers.37.mlp.fc1.weight:  31%|███       | 134/439 [00:01<00:02, 124.02w/s, dev=1]model.vision.transformer.layers.37.mlp.fc1.weight:  31%|███       | 135/439 [00:01<00:02, 122.42w/s, dev=1]model.vision.transformer.layers.37.mlp.fc2.bias:  31%|███       | 135/439 [00:01<00:02, 122.40w/s, dev=1]  model.vision.transformer.layers.37.mlp.fc2.weight:  31%|███       | 136/439 [00:01<00:02, 123.27w/s, dev=1]model.vision.transformer.layers.37.post_attention_layernorm.bias:  31%|███       | 137/439 [00:01<00:02, 121.70w/s, dev=1]model.vision.transformer.layers.37.post_attention_layernorm.weight:  31%|███▏      | 138/439 [00:01<00:02, 122.55w/s, dev=1]model.vision.transformer.layers.38.attention.dense.bias:  32%|███▏      | 139/439 [00:01<00:02, 123.42w/s, dev=1]           model.vision.transformer.layers.38.attention.dense.weight:  32%|███▏      | 140/439 [00:01<00:02, 124.29w/s, dev=1]model.vision.transformer.layers.38.attention.query_key_value.bias:  32%|███▏      | 141/439 [00:01<00:02, 124.80w/s, dev=1]model.vision.transformer.layers.38.attention.query_key_value.weight:  32%|███▏      | 142/439 [00:01<00:02, 125.66w/s, dev=1]model.vision.transformer.layers.38.input_layernorm.bias:  33%|███▎      | 143/439 [00:01<00:02, 125.63w/s, dev=1]            model.vision.transformer.layers.38.input_layernorm.weight:  33%|███▎      | 144/439 [00:01<00:02, 126.48w/s, dev=1]model.vision.transformer.layers.38.mlp.fc1.bias:  33%|███▎      | 145/439 [00:01<00:02, 127.35w/s, dev=1]          model.vision.transformer.layers.38.mlp.fc1.weight:  33%|███▎      | 146/439 [00:01<00:02, 128.21w/s, dev=1]model.vision.transformer.layers.38.mlp.fc2.bias:  33%|███▎      | 147/439 [00:01<00:02, 126.62w/s, dev=1]  model.vision.transformer.layers.38.mlp.fc2.weight:  34%|███▎      | 148/439 [00:01<00:02, 127.44w/s, dev=1]model.vision.transformer.layers.38.post_attention_layernorm.bias:  34%|███▍      | 149/439 [00:01<00:02, 125.88w/s, dev=1]model.vision.transformer.layers.38.post_attention_layernorm.weight:  34%|███▍      | 150/439 [00:01<00:02, 126.69w/s, dev=1]model.vision.transformer.layers.39.attention.dense.bias:  34%|███▍      | 151/439 [00:01<00:02, 127.51w/s, dev=1]           model.vision.transformer.layers.39.attention.dense.weight:  35%|███▍      | 152/439 [00:01<00:02, 128.34w/s, dev=1]model.vision.transformer.layers.39.attention.query_key_value.bias:  35%|███▍      | 153/439 [00:01<00:02, 128.86w/s, dev=1]model.vision.transformer.layers.39.attention.query_key_value.weight:  35%|███▌      | 154/439 [00:01<00:02, 129.67w/s, dev=1]model.vision.transformer.layers.39.input_layernorm.bias:  35%|███▌      | 155/439 [00:01<00:02, 129.61w/s, dev=1]            model.vision.transformer.layers.39.input_layernorm.weight:  36%|███▌      | 156/439 [00:01<00:02, 130.42w/s, dev=1]model.vision.transformer.layers.39.mlp.fc1.bias:  36%|███▌      | 157/439 [00:01<00:02, 131.24w/s, dev=1]          model.vision.transformer.layers.39.mlp.fc1.weight:  36%|███▌      | 158/439 [00:01<00:02, 132.06w/s, dev=1]model.vision.transformer.layers.39.mlp.fc1.weight:  36%|███▌      | 159/439 [00:01<00:02, 130.48w/s, dev=1]model.vision.transformer.layers.39.mlp.fc2.bias:  36%|███▌      | 159/439 [00:01<00:02, 130.46w/s, dev=1]  model.vision.transformer.layers.39.mlp.fc2.weight:  36%|███▋      | 160/439 [00:01<00:02, 131.25w/s, dev=1]model.vision.transformer.layers.39.post_attention_layernorm.bias:  37%|███▋      | 161/439 [00:01<00:02, 129.68w/s, dev=1]model.vision.transformer.layers.39.post_attention_layernorm.weight:  37%|███▋      | 162/439 [00:01<00:02, 130.44w/s, dev=1]model.vision.transformer.layers.40.attention.dense.bias:  37%|███▋      | 163/439 [00:01<00:02, 131.23w/s, dev=1]           model.vision.transformer.layers.40.attention.dense.weight:  37%|███▋      | 164/439 [00:01<00:02, 132.02w/s, dev=1]model.vision.transformer.layers.40.attention.query_key_value.bias:  38%|███▊      | 165/439 [00:01<00:02, 132.50w/s, dev=1]model.vision.transformer.layers.40.attention.query_key_value.weight:  38%|███▊      | 166/439 [00:01<00:02, 133.28w/s, dev=1]model.vision.transformer.layers.40.input_layernorm.bias:  38%|███▊      | 167/439 [00:01<00:02, 133.19w/s, dev=1]            model.vision.transformer.layers.40.input_layernorm.weight:  38%|███▊      | 168/439 [00:01<00:02, 133.96w/s, dev=1]model.vision.transformer.layers.40.mlp.fc1.bias:  38%|███▊      | 169/439 [00:01<00:02, 134.74w/s, dev=1]          model.vision.transformer.layers.40.mlp.fc1.weight:  39%|███▊      | 170/439 [00:01<00:01, 135.52w/s, dev=1]model.vision.transformer.layers.40.mlp.fc2.bias:  39%|███▉      | 171/439 [00:01<00:02, 133.93w/s, dev=1]  model.vision.transformer.layers.40.mlp.fc2.weight:  39%|███▉      | 172/439 [00:01<00:01, 134.68w/s, dev=1]model.vision.transformer.layers.40.post_attention_layernorm.bias:  39%|███▉      | 173/439 [00:01<00:01, 133.13w/s, dev=1]model.vision.transformer.layers.40.post_attention_layernorm.weight:  40%|███▉      | 174/439 [00:01<00:01, 133.86w/s, dev=1]model.vision.transformer.layers.41.attention.dense.bias:  40%|███▉      | 175/439 [00:01<00:01, 134.61w/s, dev=1]           model.vision.transformer.layers.41.attention.dense.weight:  40%|████      | 176/439 [00:01<00:01, 135.36w/s, dev=1]model.vision.transformer.layers.41.attention.query_key_value.bias:  40%|████      | 177/439 [00:01<00:01, 135.79w/s, dev=1]model.vision.transformer.layers.41.attention.query_key_value.weight:  41%|████      | 178/439 [00:01<00:01, 136.53w/s, dev=1]model.vision.transformer.layers.41.input_layernorm.bias:  41%|████      | 179/439 [00:01<00:01, 136.44w/s, dev=1]            model.vision.transformer.layers.41.input_layernorm.weight:  41%|████      | 180/439 [00:01<00:01, 137.18w/s, dev=1]model.vision.transformer.layers.41.mlp.fc1.bias:  41%|████      | 181/439 [00:01<00:01, 137.93w/s, dev=1]          model.vision.transformer.layers.41.mlp.fc1.weight:  41%|████▏     | 182/439 [00:01<00:01, 138.67w/s, dev=1]model.vision.transformer.layers.41.mlp.fc1.weight:  42%|████▏     | 183/439 [00:01<00:01, 137.11w/s, dev=1]model.vision.transformer.layers.41.mlp.fc2.bias:  42%|████▏     | 183/439 [00:01<00:01, 137.10w/s, dev=1]  model.vision.transformer.layers.41.mlp.fc2.weight:  42%|████▏     | 184/439 [00:01<00:01, 137.81w/s, dev=1]model.vision.transformer.layers.41.post_attention_layernorm.bias:  42%|████▏     | 185/439 [00:01<00:01, 136.28w/s, dev=1]model.vision.transformer.layers.41.post_attention_layernorm.weight:  42%|████▏     | 186/439 [00:01<00:01, 136.59w/s, dev=1]model.vision.transformer.layers.42.attention.dense.bias:  43%|████▎     | 187/439 [00:01<00:01, 137.31w/s, dev=1]           model.vision.transformer.layers.42.attention.dense.weight:  43%|████▎     | 188/439 [00:01<00:01, 138.03w/s, dev=1]model.vision.transformer.layers.42.attention.query_key_value.bias:  43%|████▎     | 189/439 [00:01<00:01, 138.46w/s, dev=1]model.vision.transformer.layers.42.attention.query_key_value.weight:  43%|████▎     | 190/439 [00:01<00:01, 139.17w/s, dev=1]model.vision.transformer.layers.42.input_layernorm.bias:  44%|████▎     | 191/439 [00:01<00:01, 139.06w/s, dev=1]            model.vision.transformer.layers.42.input_layernorm.weight:  44%|████▎     | 192/439 [00:01<00:01, 139.76w/s, dev=1]model.vision.transformer.layers.42.mlp.fc1.bias:  44%|████▍     | 193/439 [00:01<00:01, 140.48w/s, dev=1]          model.vision.transformer.layers.42.mlp.fc1.weight:  44%|████▍     | 194/439 [00:01<00:01, 141.19w/s, dev=1]model.vision.transformer.layers.42.mlp.fc2.bias:  44%|████▍     | 195/439 [00:01<00:01, 139.64w/s, dev=1]  model.vision.transformer.layers.42.mlp.fc2.weight:  45%|████▍     | 196/439 [00:01<00:01, 140.32w/s, dev=1]model.vision.transformer.layers.42.post_attention_layernorm.bias:  45%|████▍     | 197/439 [00:01<00:01, 138.83w/s, dev=1]model.vision.transformer.layers.42.post_attention_layernorm.weight:  45%|████▌     | 198/439 [00:01<00:01, 139.50w/s, dev=1]model.vision.transformer.layers.43.attention.dense.bias:  45%|████▌     | 199/439 [00:01<00:01, 140.18w/s, dev=1]           model.vision.transformer.layers.43.attention.dense.weight:  46%|████▌     | 200/439 [00:01<00:01, 140.87w/s, dev=1]model.vision.transformer.layers.43.attention.query_key_value.bias:  46%|████▌     | 201/439 [00:01<00:01, 141.28w/s, dev=1]model.vision.transformer.layers.43.attention.query_key_value.weight:  46%|████▌     | 202/439 [00:01<00:01, 141.96w/s, dev=1]model.vision.transformer.layers.43.input_layernorm.bias:  46%|████▌     | 203/439 [00:01<00:01, 141.85w/s, dev=1]            model.vision.transformer.layers.43.input_layernorm.weight:  46%|████▋     | 204/439 [00:01<00:01, 142.52w/s, dev=1]model.vision.transformer.layers.43.mlp.fc1.bias:  47%|████▋     | 205/439 [00:01<00:01, 143.21w/s, dev=1]          model.vision.transformer.layers.43.mlp.fc1.weight:  47%|████▋     | 206/439 [00:01<00:01, 143.89w/s, dev=1]model.vision.transformer.layers.43.mlp.fc1.weight:  47%|████▋     | 207/439 [00:01<00:01, 142.42w/s, dev=1]model.vision.transformer.layers.43.mlp.fc2.bias:  47%|████▋     | 207/439 [00:01<00:01, 142.40w/s, dev=1]  model.vision.transformer.layers.43.mlp.fc2.weight:  47%|████▋     | 208/439 [00:01<00:01, 143.06w/s, dev=1]model.vision.transformer.layers.43.post_attention_layernorm.bias:  48%|████▊     | 209/439 [00:01<00:01, 141.65w/s, dev=1]model.vision.transformer.layers.43.post_attention_layernorm.weight:  48%|████▊     | 210/439 [00:01<00:01, 142.29w/s, dev=1]model.vision.transformer.layers.44.attention.dense.bias:  48%|████▊     | 211/439 [00:01<00:01, 142.95w/s, dev=1]           model.vision.transformer.layers.44.attention.dense.weight:  48%|████▊     | 212/439 [00:01<00:01, 143.62w/s, dev=1]model.vision.transformer.layers.44.attention.query_key_value.bias:  49%|████▊     | 213/439 [00:01<00:01, 143.99w/s, dev=1]model.vision.transformer.layers.44.attention.query_key_value.weight:  49%|████▊     | 214/439 [00:01<00:01, 144.64w/s, dev=1]model.vision.transformer.layers.44.input_layernorm.bias:  49%|████▉     | 215/439 [00:01<00:01, 144.58w/s, dev=1]            model.vision.transformer.layers.44.input_layernorm.weight:  49%|████▉     | 216/439 [00:01<00:01, 145.23w/s, dev=1]model.vision.transformer.layers.44.mlp.fc1.bias:  49%|████▉     | 217/439 [00:01<00:01, 145.89w/s, dev=1]          model.vision.transformer.layers.44.mlp.fc1.weight:  50%|████▉     | 218/439 [00:01<00:01, 146.54w/s, dev=1]model.vision.transformer.layers.44.mlp.fc2.bias:  50%|████▉     | 219/439 [00:01<00:01, 144.31w/s, dev=1]  model.vision.transformer.layers.44.mlp.fc2.weight:  50%|█████     | 220/439 [00:01<00:01, 144.93w/s, dev=1]model.vision.transformer.layers.44.post_attention_layernorm.bias:  50%|█████     | 221/439 [00:01<00:01, 143.28w/s, dev=1]model.vision.transformer.layers.44.post_attention_layernorm.weight:  51%|█████     | 222/439 [00:01<00:01, 143.89w/s, dev=1]model.vision.transformer.layers.45.attention.dense.bias:  51%|█████     | 223/439 [00:01<00:01, 144.52w/s, dev=1]           model.vision.transformer.layers.45.attention.dense.weight:  51%|█████     | 224/439 [00:01<00:01, 145.16w/s, dev=1]model.vision.transformer.layers.45.attention.query_key_value.bias:  51%|█████▏    | 225/439 [00:01<00:01, 145.53w/s, dev=1]model.vision.transformer.layers.45.attention.query_key_value.weight:  51%|█████▏    | 226/439 [00:01<00:01, 146.16w/s, dev=1]model.vision.transformer.layers.45.input_layernorm.bias:  52%|█████▏    | 227/439 [00:01<00:01, 145.89w/s, dev=1]            model.vision.transformer.layers.45.input_layernorm.weight:  52%|█████▏    | 228/439 [00:01<00:01, 146.50w/s, dev=1]model.vision.transformer.layers.45.mlp.fc1.bias:  52%|█████▏    | 229/439 [00:01<00:01, 147.13w/s, dev=1]          model.vision.transformer.layers.45.mlp.fc1.weight:  52%|█████▏    | 230/439 [00:01<00:01, 147.75w/s, dev=1]model.vision.transformer.layers.45.mlp.fc1.weight:  53%|█████▎    | 231/439 [00:01<00:01, 145.72w/s, dev=1]model.vision.transformer.layers.45.mlp.fc2.bias:  53%|█████▎    | 231/439 [00:01<00:01, 145.70w/s, dev=1]  model.vision.transformer.layers.45.mlp.fc2.weight:  53%|█████▎    | 232/439 [00:01<00:01, 146.30w/s, dev=1]model.vision.transformer.layers.45.post_attention_layernorm.bias:  53%|█████▎    | 233/439 [00:01<00:01, 143.82w/s, dev=1]model.vision.transformer.layers.45.post_attention_layernorm.weight:  53%|█████▎    | 234/439 [00:01<00:01, 144.40w/s, dev=1]model.vision.transformer.layers.46.attention.dense.bias:  54%|█████▎    | 235/439 [00:01<00:01, 145.01w/s, dev=1]           model.vision.transformer.layers.46.attention.dense.weight:  54%|█████▍    | 236/439 [00:01<00:01, 145.61w/s, dev=1]model.vision.transformer.layers.46.attention.query_key_value.bias:  54%|█████▍    | 237/439 [00:01<00:01, 145.61w/s, dev=1]model.vision.transformer.layers.46.attention.query_key_value.weight:  54%|█████▍    | 238/439 [00:01<00:01, 146.20w/s, dev=1]model.vision.transformer.layers.46.input_layernorm.bias:  54%|█████▍    | 239/439 [00:01<00:01, 146.11w/s, dev=1]            model.vision.transformer.layers.46.input_layernorm.weight:  55%|█████▍    | 240/439 [00:01<00:01, 146.70w/s, dev=1]model.vision.transformer.layers.46.mlp.fc1.bias:  55%|█████▍    | 241/439 [00:01<00:01, 147.30w/s, dev=1]          model.vision.transformer.layers.46.mlp.fc1.weight:  55%|█████▌    | 242/439 [00:01<00:01, 147.90w/s, dev=1]model.vision.transformer.layers.46.mlp.fc2.bias:  55%|█████▌    | 243/439 [00:01<00:01, 145.68w/s, dev=1]  model.vision.transformer.layers.46.mlp.fc2.weight:  56%|█████▌    | 244/439 [00:01<00:01, 146.24w/s, dev=1]model.vision.transformer.layers.46.post_attention_layernorm.bias:  56%|█████▌    | 245/439 [00:01<00:01, 144.62w/s, dev=1]model.vision.transformer.layers.46.post_attention_layernorm.weight:  56%|█████▌    | 246/439 [00:01<00:01, 145.17w/s, dev=1]model.vision.transformer.layers.47.attention.dense.bias:  56%|█████▋    | 247/439 [00:01<00:01, 145.75w/s, dev=1]           model.vision.transformer.layers.47.attention.dense.weight:  56%|█████▋    | 248/439 [00:01<00:01, 146.32w/s, dev=1]model.vision.transformer.layers.47.attention.query_key_value.bias:  57%|█████▋    | 249/439 [00:01<00:01, 146.64w/s, dev=1]model.vision.transformer.layers.47.attention.query_key_value.weight:  57%|█████▋    | 250/439 [00:01<00:01, 147.21w/s, dev=1]model.vision.transformer.layers.47.input_layernorm.bias:  57%|█████▋    | 251/439 [00:01<00:01, 147.14w/s, dev=1]            model.vision.transformer.layers.47.input_layernorm.weight:  57%|█████▋    | 252/439 [00:01<00:01, 147.71w/s, dev=1]model.vision.transformer.layers.47.mlp.fc1.bias:  58%|█████▊    | 253/439 [00:01<00:01, 148.28w/s, dev=1]          model.vision.transformer.layers.47.mlp.fc1.weight:  58%|█████▊    | 254/439 [00:01<00:01, 148.85w/s, dev=1]model.vision.transformer.layers.47.mlp.fc1.weight:  58%|█████▊    | 255/439 [00:01<00:01, 146.79w/s, dev=1]model.vision.transformer.layers.47.mlp.fc2.bias:  58%|█████▊    | 255/439 [00:01<00:01, 146.77w/s, dev=1]  model.vision.transformer.layers.47.mlp.fc2.weight:  58%|█████▊    | 256/439 [00:01<00:01, 147.32w/s, dev=1]model.vision.transformer.layers.47.post_attention_layernorm.bias:  59%|█████▊    | 257/439 [00:01<00:01, 145.78w/s, dev=1]model.vision.transformer.layers.47.post_attention_layernorm.weight:  59%|█████▉    | 258/439 [00:01<00:01, 146.31w/s, dev=1]model.vision.transformer.layers.48.attention.dense.bias:  59%|█████▉    | 259/439 [00:01<00:01, 146.86w/s, dev=1]           model.vision.transformer.layers.48.attention.dense.weight:  59%|█████▉    | 260/439 [00:01<00:01, 147.42w/s, dev=1]model.vision.transformer.layers.48.attention.query_key_value.bias:  59%|█████▉    | 261/439 [00:01<00:01, 147.76w/s, dev=1]model.vision.transformer.layers.48.attention.query_key_value.weight:  60%|█████▉    | 262/439 [00:01<00:01, 148.30w/s, dev=1]model.vision.transformer.layers.48.input_layernorm.bias:  60%|█████▉    | 263/439 [00:01<00:01, 147.83w/s, dev=1]            model.vision.transformer.layers.48.input_layernorm.weight:  60%|██████    | 264/439 [00:01<00:01, 148.37w/s, dev=1]model.vision.transformer.layers.48.mlp.fc1.bias:  60%|██████    | 265/439 [00:01<00:01, 148.91w/s, dev=1]          model.vision.transformer.layers.48.mlp.fc1.weight:  61%|██████    | 266/439 [00:01<00:01, 149.46w/s, dev=1]model.vision.transformer.layers.48.mlp.fc2.bias:  61%|██████    | 267/439 [00:01<00:01, 147.85w/s, dev=1]  model.vision.transformer.layers.48.mlp.fc2.weight:  61%|██████    | 268/439 [00:01<00:01, 148.37w/s, dev=1]model.vision.transformer.layers.48.post_attention_layernorm.bias:  61%|██████▏   | 269/439 [00:01<00:01, 146.79w/s, dev=1]model.vision.transformer.layers.48.post_attention_layernorm.weight:  62%|██████▏   | 270/439 [00:01<00:01, 147.30w/s, dev=1]model.vision.transformer.layers.49.attention.dense.bias:  62%|██████▏   | 271/439 [00:01<00:01, 147.83w/s, dev=1]           model.vision.transformer.layers.49.attention.dense.weight:  62%|██████▏   | 272/439 [00:01<00:01, 148.36w/s, dev=1]model.vision.transformer.layers.49.attention.query_key_value.bias:  62%|██████▏   | 273/439 [00:01<00:01, 148.67w/s, dev=1]model.vision.transformer.layers.49.attention.query_key_value.weight:  62%|██████▏   | 274/439 [00:01<00:01, 149.20w/s, dev=1]model.vision.transformer.layers.49.input_layernorm.bias:  63%|██████▎   | 275/439 [00:01<00:01, 148.44w/s, dev=1]            model.vision.transformer.layers.49.input_layernorm.weight:  63%|██████▎   | 276/439 [00:01<00:01, 148.95w/s, dev=1]model.vision.transformer.layers.49.mlp.fc1.bias:  63%|██████▎   | 277/439 [00:01<00:01, 149.47w/s, dev=1]          model.vision.transformer.layers.49.mlp.fc1.weight:  63%|██████▎   | 278/439 [00:01<00:01, 150.00w/s, dev=1]model.vision.transformer.layers.49.mlp.fc1.weight:  64%|██████▎   | 279/439 [00:01<00:01, 148.83w/s, dev=1]model.vision.transformer.layers.49.mlp.fc2.bias:  64%|██████▎   | 279/439 [00:01<00:01, 148.81w/s, dev=1]  model.vision.transformer.layers.49.mlp.fc2.weight:  64%|██████▍   | 280/439 [00:01<00:01, 149.32w/s, dev=1]model.vision.transformer.layers.49.post_attention_layernorm.bias:  64%|██████▍   | 281/439 [00:01<00:01, 147.51w/s, dev=1]model.vision.transformer.layers.49.post_attention_layernorm.weight:  64%|██████▍   | 282/439 [00:01<00:01, 148.00w/s, dev=1]model.vision.transformer.layers.50.attention.dense.bias:  64%|██████▍   | 283/439 [00:01<00:01, 148.52w/s, dev=1]           model.vision.transformer.layers.50.attention.dense.weight:  65%|██████▍   | 284/439 [00:01<00:01, 149.03w/s, dev=1]model.vision.transformer.layers.50.attention.query_key_value.bias:  65%|██████▍   | 285/439 [00:01<00:01, 149.30w/s, dev=1]model.vision.transformer.layers.50.attention.query_key_value.weight:  65%|██████▌   | 286/439 [00:01<00:01, 149.81w/s, dev=1]model.vision.transformer.layers.50.input_layernorm.bias:  65%|██████▌   | 287/439 [00:01<00:01, 149.48w/s, dev=1]            model.vision.transformer.layers.50.input_layernorm.weight:  66%|██████▌   | 288/439 [00:01<00:01, 149.97w/s, dev=1]model.vision.transformer.layers.50.mlp.fc1.bias:  66%|██████▌   | 289/439 [00:01<00:00, 150.48w/s, dev=1]          model.vision.transformer.layers.50.mlp.fc1.weight:  66%|██████▌   | 290/439 [00:01<00:00, 150.99w/s, dev=1]model.vision.transformer.layers.50.mlp.fc2.bias:  66%|██████▋   | 291/439 [00:01<00:00, 149.62w/s, dev=1]  model.vision.transformer.layers.50.mlp.fc2.weight:  67%|██████▋   | 292/439 [00:01<00:00, 150.10w/s, dev=1]model.vision.transformer.layers.50.post_attention_layernorm.bias:  67%|██████▋   | 293/439 [00:01<00:00, 148.08w/s, dev=1]model.vision.transformer.layers.50.post_attention_layernorm.weight:  67%|██████▋   | 294/439 [00:01<00:00, 148.55w/s, dev=1]model.vision.transformer.layers.51.attention.dense.bias:  67%|██████▋   | 295/439 [00:01<00:00, 149.04w/s, dev=1]           model.vision.transformer.layers.51.attention.dense.weight:  67%|██████▋   | 296/439 [00:01<00:00, 149.53w/s, dev=1]model.vision.transformer.layers.51.attention.query_key_value.bias:  68%|██████▊   | 297/439 [00:01<00:00, 149.82w/s, dev=1]model.vision.transformer.layers.51.attention.query_key_value.weight:  68%|██████▊   | 298/439 [00:01<00:00, 150.31w/s, dev=1]model.vision.transformer.layers.51.input_layernorm.bias:  68%|██████▊   | 299/439 [00:01<00:00, 150.22w/s, dev=1]            model.vision.transformer.layers.51.input_layernorm.weight:  68%|██████▊   | 300/439 [00:01<00:00, 150.71w/s, dev=1]model.vision.transformer.layers.51.mlp.fc1.bias:  69%|██████▊   | 301/439 [00:01<00:00, 151.20w/s, dev=1]          model.vision.transformer.layers.51.mlp.fc1.weight:  69%|██████▉   | 302/439 [00:01<00:00, 151.69w/s, dev=1]model.vision.transformer.layers.51.mlp.fc1.weight:  69%|██████▉   | 303/439 [00:02<00:00, 149.73w/s, dev=1]model.vision.transformer.layers.51.mlp.fc2.bias:  69%|██████▉   | 303/439 [00:02<00:00, 149.71w/s, dev=1]  model.vision.transformer.layers.51.mlp.fc2.weight:  69%|██████▉   | 304/439 [00:02<00:00, 150.18w/s, dev=1]model.vision.transformer.layers.51.post_attention_layernorm.bias:  69%|██████▉   | 305/439 [00:02<00:00, 148.83w/s, dev=1]model.vision.transformer.layers.51.post_attention_layernorm.weight:  70%|██████▉   | 306/439 [00:02<00:00, 149.29w/s, dev=1]model.vision.transformer.layers.52.attention.dense.bias:  70%|██████▉   | 307/439 [00:02<00:00, 149.77w/s, dev=1]           model.vision.transformer.layers.52.attention.dense.weight:  70%|███████   | 308/439 [00:02<00:00, 150.24w/s, dev=1]model.vision.transformer.layers.52.attention.query_key_value.bias:  70%|███████   | 309/439 [00:02<00:00, 150.10w/s, dev=1]model.vision.transformer.layers.52.attention.query_key_value.weight:  71%|███████   | 310/439 [00:02<00:00, 150.56w/s, dev=1]model.vision.transformer.layers.52.input_layernorm.bias:  71%|███████   | 311/439 [00:02<00:00, 150.49w/s, dev=1]            model.vision.transformer.layers.52.input_layernorm.weight:  71%|███████   | 312/439 [00:02<00:00, 150.95w/s, dev=1]model.vision.transformer.layers.52.mlp.fc1.bias:  71%|███████▏  | 313/439 [00:02<00:00, 151.43w/s, dev=1]          model.vision.transformer.layers.52.mlp.fc1.weight:  72%|███████▏  | 314/439 [00:02<00:00, 151.90w/s, dev=1]model.vision.transformer.layers.52.mlp.fc2.bias:  72%|███████▏  | 315/439 [00:02<00:00, 150.18w/s, dev=1]  model.vision.transformer.layers.52.mlp.fc2.weight:  72%|███████▏  | 316/439 [00:02<00:00, 150.62w/s, dev=1]model.vision.transformer.layers.52.post_attention_layernorm.bias:  72%|███████▏  | 317/439 [00:02<00:00, 149.11w/s, dev=1]model.vision.transformer.layers.52.post_attention_layernorm.weight:  72%|███████▏  | 318/439 [00:02<00:00, 149.55w/s, dev=1]model.vision.transformer.layers.53.attention.dense.bias:  73%|███████▎  | 319/439 [00:02<00:00, 150.01w/s, dev=1]           model.vision.transformer.layers.53.attention.dense.weight:  73%|███████▎  | 320/439 [00:02<00:00, 150.47w/s, dev=1]model.vision.transformer.layers.53.attention.query_key_value.bias:  73%|███████▎  | 321/439 [00:02<00:00, 150.72w/s, dev=1]model.vision.transformer.layers.53.attention.query_key_value.weight:  73%|███████▎  | 322/439 [00:02<00:00, 151.17w/s, dev=1]model.vision.transformer.layers.53.input_layernorm.bias:  74%|███████▎  | 323/439 [00:02<00:00, 151.12w/s, dev=1]            model.vision.transformer.layers.53.input_layernorm.weight:  74%|███████▍  | 324/439 [00:02<00:00, 151.57w/s, dev=1]model.vision.transformer.layers.53.mlp.fc1.bias:  74%|███████▍  | 325/439 [00:02<00:00, 152.03w/s, dev=1]          model.vision.transformer.layers.53.mlp.fc1.weight:  74%|███████▍  | 326/439 [00:02<00:00, 152.48w/s, dev=1]model.vision.transformer.layers.53.mlp.fc1.weight:  74%|███████▍  | 327/439 [00:02<00:00, 150.63w/s, dev=1]model.vision.transformer.layers.53.mlp.fc2.bias:  74%|███████▍  | 327/439 [00:02<00:00, 150.61w/s, dev=1]  model.vision.transformer.layers.53.mlp.fc2.weight:  75%|███████▍  | 328/439 [00:02<00:00, 151.05w/s, dev=1]model.vision.transformer.layers.53.post_attention_layernorm.bias:  75%|███████▍  | 329/439 [00:02<00:00, 149.94w/s, dev=1]model.vision.transformer.layers.53.post_attention_layernorm.weight:  75%|███████▌  | 330/439 [00:02<00:00, 150.37w/s, dev=1]model.vision.transformer.layers.54.attention.dense.bias:  75%|███████▌  | 331/439 [00:02<00:00, 150.81w/s, dev=1]           model.vision.transformer.layers.54.attention.dense.weight:  76%|███████▌  | 332/439 [00:02<00:00, 151.26w/s, dev=1]model.vision.transformer.layers.54.attention.query_key_value.bias:  76%|███████▌  | 333/439 [00:02<00:00, 151.37w/s, dev=1]model.vision.transformer.layers.54.attention.query_key_value.weight:  76%|███████▌  | 334/439 [00:02<00:00, 151.81w/s, dev=1]model.vision.transformer.layers.54.input_layernorm.bias:  76%|███████▋  | 335/439 [00:02<00:00, 151.50w/s, dev=1]            model.vision.transformer.layers.54.input_layernorm.weight:  77%|███████▋  | 336/439 [00:02<00:00, 151.93w/s, dev=1]model.vision.transformer.layers.54.mlp.fc1.bias:  77%|███████▋  | 337/439 [00:02<00:00, 152.37w/s, dev=1]          model.vision.transformer.layers.54.mlp.fc1.weight:  77%|███████▋  | 338/439 [00:02<00:00, 152.81w/s, dev=1]model.vision.transformer.layers.54.mlp.fc2.bias:  77%|███████▋  | 339/439 [00:02<00:00, 151.55w/s, dev=1]  model.vision.transformer.layers.54.mlp.fc2.weight:  77%|███████▋  | 340/439 [00:02<00:00, 151.97w/s, dev=1]model.vision.transformer.layers.54.post_attention_layernorm.bias:  78%|███████▊  | 341/439 [00:02<00:00, 150.44w/s, dev=1]model.vision.transformer.layers.54.post_attention_layernorm.weight:  78%|███████▊  | 342/439 [00:02<00:00, 150.85w/s, dev=1]model.vision.transformer.layers.55.attention.dense.bias:  78%|███████▊  | 343/439 [00:02<00:00, 151.28w/s, dev=1]           model.vision.transformer.layers.55.attention.dense.weight:  78%|███████▊  | 344/439 [00:02<00:00, 151.71w/s, dev=1]model.vision.transformer.layers.55.attention.query_key_value.bias:  79%|███████▊  | 345/439 [00:02<00:00, 151.97w/s, dev=1]model.vision.transformer.layers.55.attention.query_key_value.weight:  79%|███████▉  | 346/439 [00:02<00:00, 152.39w/s, dev=1]model.vision.transformer.layers.55.input_layernorm.bias:  79%|███████▉  | 347/439 [00:02<00:00, 152.14w/s, dev=1]            model.vision.transformer.layers.55.input_layernorm.weight:  79%|███████▉  | 348/439 [00:02<00:00, 152.56w/s, dev=1]model.vision.transformer.layers.55.mlp.fc1.bias:  79%|███████▉  | 349/439 [00:02<00:00, 152.99w/s, dev=1]          model.vision.transformer.layers.55.mlp.fc1.weight:  80%|███████▉  | 350/439 [00:02<00:00, 153.41w/s, dev=1]model.vision.transformer.layers.55.mlp.fc1.weight:  80%|███████▉  | 351/439 [00:02<00:00, 151.86w/s, dev=1]model.vision.transformer.layers.55.mlp.fc2.bias:  80%|███████▉  | 351/439 [00:02<00:00, 151.85w/s, dev=1]  model.vision.transformer.layers.55.mlp.fc2.weight:  80%|████████  | 352/439 [00:02<00:00, 152.26w/s, dev=1]model.vision.transformer.layers.55.post_attention_layernorm.bias:  80%|████████  | 353/439 [00:02<00:00, 150.75w/s, dev=1]model.vision.transformer.layers.55.post_attention_layernorm.weight:  81%|████████  | 354/439 [00:02<00:00, 151.15w/s, dev=1]model.vision.transformer.layers.56.attention.dense.bias:  81%|████████  | 355/439 [00:02<00:00, 151.57w/s, dev=1]           model.vision.transformer.layers.56.attention.dense.weight:  81%|████████  | 356/439 [00:02<00:00, 151.99w/s, dev=1]model.vision.transformer.layers.56.attention.query_key_value.bias:  81%|████████▏ | 357/439 [00:02<00:00, 152.21w/s, dev=1]model.vision.transformer.layers.56.attention.query_key_value.weight:  82%|████████▏ | 358/439 [00:02<00:00, 152.62w/s, dev=1]model.vision.transformer.layers.56.input_layernorm.bias:  82%|████████▏ | 359/439 [00:02<00:00, 152.31w/s, dev=1]            model.vision.transformer.layers.56.input_layernorm.weight:  82%|████████▏ | 360/439 [00:02<00:00, 152.72w/s, dev=1]model.vision.transformer.layers.56.mlp.fc1.bias:  82%|████████▏ | 361/439 [00:02<00:00, 153.13w/s, dev=1]          model.vision.transformer.layers.56.mlp.fc1.weight:  82%|████████▏ | 362/439 [00:02<00:00, 153.54w/s, dev=1]model.vision.transformer.layers.56.mlp.fc2.bias:  83%|████████▎ | 363/439 [00:02<00:00, 152.29w/s, dev=1]  model.vision.transformer.layers.56.mlp.fc2.weight:  83%|████████▎ | 364/439 [00:02<00:00, 152.69w/s, dev=1]model.vision.transformer.layers.56.post_attention_layernorm.bias:  83%|████████▎ | 365/439 [00:02<00:00, 151.33w/s, dev=1]model.vision.transformer.layers.56.post_attention_layernorm.weight:  83%|████████▎ | 366/439 [00:02<00:00, 151.72w/s, dev=1]model.vision.transformer.layers.57.attention.dense.bias:  84%|████████▎ | 367/439 [00:02<00:00, 152.13w/s, dev=1]           model.vision.transformer.layers.57.attention.dense.weight:  84%|████████▍ | 368/439 [00:02<00:00, 152.53w/s, dev=1]model.vision.transformer.layers.57.attention.query_key_value.bias:  84%|████████▍ | 369/439 [00:02<00:00, 152.77w/s, dev=1]model.vision.transformer.layers.57.attention.query_key_value.weight:  84%|████████▍ | 370/439 [00:02<00:00, 153.17w/s, dev=1]model.vision.transformer.layers.57.input_layernorm.bias:  85%|████████▍ | 371/439 [00:02<00:00, 153.10w/s, dev=1]            model.vision.transformer.layers.57.input_layernorm.weight:  85%|████████▍ | 372/439 [00:02<00:00, 153.50w/s, dev=1]model.vision.transformer.layers.57.mlp.fc1.bias:  85%|████████▍ | 373/439 [00:02<00:00, 153.90w/s, dev=1]          model.vision.transformer.layers.57.mlp.fc1.weight:  85%|████████▌ | 374/439 [00:02<00:00, 154.30w/s, dev=1]model.vision.transformer.layers.57.mlp.fc1.weight:  85%|████████▌ | 375/439 [00:02<00:00, 152.91w/s, dev=1]model.vision.transformer.layers.57.mlp.fc2.bias:  85%|████████▌ | 375/439 [00:02<00:00, 152.90w/s, dev=1]  model.vision.transformer.layers.57.mlp.fc2.weight:  86%|████████▌ | 376/439 [00:02<00:00, 153.29w/s, dev=1]model.vision.transformer.layers.57.post_attention_layernorm.bias:  86%|████████▌ | 377/439 [00:02<00:00, 151.56w/s, dev=1]model.vision.transformer.layers.57.post_attention_layernorm.weight:  86%|████████▌ | 378/439 [00:02<00:00, 151.94w/s, dev=1]model.vision.transformer.layers.58.attention.dense.bias:  86%|████████▋ | 379/439 [00:02<00:00, 152.33w/s, dev=1]           model.vision.transformer.layers.58.attention.dense.weight:  87%|████████▋ | 380/439 [00:02<00:00, 152.72w/s, dev=1]model.vision.transformer.layers.58.attention.query_key_value.bias:  87%|████████▋ | 381/439 [00:02<00:00, 152.95w/s, dev=1]model.vision.transformer.layers.58.attention.query_key_value.weight:  87%|████████▋ | 382/439 [00:02<00:00, 153.34w/s, dev=1]model.vision.transformer.layers.58.input_layernorm.bias:  87%|████████▋ | 383/439 [00:02<00:00, 153.26w/s, dev=1]            model.vision.transformer.layers.58.input_layernorm.weight:  87%|████████▋ | 384/439 [00:02<00:00, 153.64w/s, dev=1]model.vision.transformer.layers.58.mlp.fc1.bias:  88%|████████▊ | 385/439 [00:02<00:00, 154.03w/s, dev=1]          model.vision.transformer.layers.58.mlp.fc1.weight:  88%|████████▊ | 386/439 [00:02<00:00, 154.42w/s, dev=1]model.vision.transformer.layers.58.mlp.fc2.bias:  88%|████████▊ | 387/439 [00:02<00:00, 153.16w/s, dev=1]  model.vision.transformer.layers.58.mlp.fc2.weight:  88%|████████▊ | 388/439 [00:02<00:00, 153.53w/s, dev=1]model.vision.transformer.layers.58.post_attention_layernorm.bias:  89%|████████▊ | 389/439 [00:02<00:00, 152.02w/s, dev=1]model.vision.transformer.layers.58.post_attention_layernorm.weight:  89%|████████▉ | 390/439 [00:02<00:00, 152.39w/s, dev=1]model.vision.transformer.layers.59.attention.dense.bias:  89%|████████▉ | 391/439 [00:02<00:00, 152.77w/s, dev=1]           model.vision.transformer.layers.59.attention.dense.weight:  89%|████████▉ | 392/439 [00:02<00:00, 153.15w/s, dev=1]model.vision.transformer.layers.59.attention.query_key_value.bias:  90%|████████▉ | 393/439 [00:02<00:00, 153.36w/s, dev=1]model.vision.transformer.layers.59.attention.query_key_value.weight:  90%|████████▉ | 394/439 [00:02<00:00, 153.74w/s, dev=1]model.vision.transformer.layers.59.input_layernorm.bias:  90%|████████▉ | 395/439 [00:02<00:00, 150.61w/s, dev=1]            model.vision.transformer.layers.59.input_layernorm.weight:  90%|█████████ | 396/439 [00:02<00:00, 150.97w/s, dev=1]model.vision.transformer.layers.59.mlp.fc1.bias:  90%|█████████ | 397/439 [00:02<00:00, 151.34w/s, dev=1]          model.vision.transformer.layers.59.mlp.fc1.weight:  91%|█████████ | 398/439 [00:02<00:00, 151.72w/s, dev=1]model.vision.transformer.layers.59.mlp.fc1.weight:  91%|█████████ | 399/439 [00:02<00:00, 150.49w/s, dev=1]model.vision.transformer.layers.59.mlp.fc2.bias:  91%|█████████ | 399/439 [00:02<00:00, 150.48w/s, dev=1]  model.vision.transformer.layers.59.mlp.fc2.weight:  91%|█████████ | 400/439 [00:02<00:00, 150.83w/s, dev=1]model.vision.transformer.layers.59.post_attention_layernorm.bias:  91%|█████████▏| 401/439 [00:02<00:00, 149.46w/s, dev=1]model.vision.transformer.layers.59.post_attention_layernorm.weight:  92%|█████████▏| 402/439 [00:02<00:00, 149.81w/s, dev=1]model.vision.transformer.layers.60.attention.dense.bias:  92%|█████████▏| 403/439 [00:02<00:00, 150.17w/s, dev=1]           model.vision.transformer.layers.60.attention.dense.weight:  92%|█████████▏| 404/439 [00:02<00:00, 150.53w/s, dev=1]model.vision.transformer.layers.60.attention.query_key_value.bias:  92%|█████████▏| 405/439 [00:02<00:00, 150.74w/s, dev=1]model.vision.transformer.layers.60.attention.query_key_value.weight:  92%|█████████▏| 406/439 [00:02<00:00, 151.10w/s, dev=1]model.vision.transformer.layers.60.input_layernorm.bias:  93%|█████████▎| 407/439 [00:02<00:00, 150.79w/s, dev=1]            model.vision.transformer.layers.60.input_layernorm.weight:  93%|█████████▎| 408/439 [00:02<00:00, 151.15w/s, dev=1]model.vision.transformer.layers.60.mlp.fc1.bias:  93%|█████████▎| 409/439 [00:02<00:00, 151.51w/s, dev=1]          model.vision.transformer.layers.60.mlp.fc1.weight:  93%|█████████▎| 410/439 [00:02<00:00, 151.87w/s, dev=1]model.vision.transformer.layers.60.mlp.fc2.bias:  94%|█████████▎| 411/439 [00:02<00:00, 150.70w/s, dev=1]  model.vision.transformer.layers.60.mlp.fc2.weight:  94%|█████████▍| 412/439 [00:02<00:00, 151.04w/s, dev=1]model.vision.transformer.layers.60.post_attention_layernorm.bias:  94%|█████████▍| 413/439 [00:02<00:00, 149.93w/s, dev=1]model.vision.transformer.layers.60.post_attention_layernorm.weight:  94%|█████████▍| 414/439 [00:02<00:00, 150.27w/s, dev=1]model.vision.transformer.layers.61.attention.dense.bias:  95%|█████████▍| 415/439 [00:02<00:00, 150.62w/s, dev=1]           model.vision.transformer.layers.61.attention.dense.weight:  95%|█████████▍| 416/439 [00:02<00:00, 150.98w/s, dev=1]model.vision.transformer.layers.61.attention.query_key_value.bias:  95%|█████████▍| 417/439 [00:02<00:00, 151.18w/s, dev=1]model.vision.transformer.layers.61.attention.query_key_value.weight:  95%|█████████▌| 418/439 [00:02<00:00, 151.53w/s, dev=1]model.vision.transformer.layers.61.input_layernorm.bias:  95%|█████████▌| 419/439 [00:02<00:00, 151.41w/s, dev=1]            model.vision.transformer.layers.61.input_layernorm.weight:  96%|█████████▌| 420/439 [00:02<00:00, 151.76w/s, dev=1]model.vision.transformer.layers.61.mlp.fc1.bias:  96%|█████████▌| 421/439 [00:02<00:00, 152.11w/s, dev=1]          model.vision.transformer.layers.61.mlp.fc1.weight:  96%|█████████▌| 422/439 [00:02<00:00, 152.46w/s, dev=1]model.vision.transformer.layers.61.mlp.fc1.weight:  96%|█████████▋| 423/439 [00:02<00:00, 151.53w/s, dev=1]model.vision.transformer.layers.61.mlp.fc2.bias:  96%|█████████▋| 423/439 [00:02<00:00, 151.52w/s, dev=1]  model.vision.transformer.layers.61.mlp.fc2.weight:  97%|█████████▋| 424/439 [00:02<00:00, 151.86w/s, dev=1]model.vision.transformer.layers.61.post_attention_layernorm.bias:  97%|█████████▋| 425/439 [00:02<00:00, 150.62w/s, dev=1]model.vision.transformer.layers.61.post_attention_layernorm.weight:  97%|█████████▋| 426/439 [00:02<00:00, 150.95w/s, dev=1]model.vision.transformer.layers.62.attention.dense.bias:  97%|█████████▋| 427/439 [00:02<00:00, 151.29w/s, dev=1]           model.vision.transformer.layers.62.attention.dense.weight:  97%|█████████▋| 428/439 [00:02<00:00, 151.64w/s, dev=1]model.vision.transformer.layers.62.attention.query_key_value.bias:  98%|█████████▊| 429/439 [00:02<00:00, 151.83w/s, dev=1]model.vision.transformer.layers.62.attention.query_key_value.weight:  98%|█████████▊| 430/439 [00:02<00:00, 152.17w/s, dev=1]model.vision.transformer.layers.62.input_layernorm.bias:  98%|█████████▊| 431/439 [00:02<00:00, 152.12w/s, dev=1]            model.vision.transformer.layers.62.input_layernorm.weight:  98%|█████████▊| 432/439 [00:02<00:00, 152.46w/s, dev=1]model.vision.transformer.layers.62.mlp.fc1.bias:  99%|█████████▊| 433/439 [00:02<00:00, 152.81w/s, dev=1]          model.vision.transformer.layers.62.mlp.fc1.weight:  99%|█████████▉| 434/439 [00:02<00:00, 153.15w/s, dev=1]model.vision.transformer.layers.62.mlp.fc2.bias:  99%|█████████▉| 435/439 [00:02<00:00, 151.56w/s, dev=1]  model.vision.transformer.layers.62.mlp.fc2.weight:  99%|█████████▉| 436/439 [00:02<00:00, 151.89w/s, dev=1]model.vision.transformer.layers.62.post_attention_layernorm.bias: 100%|█████████▉| 437/439 [00:02<00:00, 150.95w/s, dev=1]model.vision.transformer.layers.62.post_attention_layernorm.weight: 100%|█████████▉| 438/439 [00:02<00:00, 151.27w/s, dev=1]                                                                                                                              0%|          | 0/4 [00:00<?, ?w/s]model.vision.linear_proj.dense_4h_to_h.weight:   0%|          | 0/4 [00:00<?, ?w/s, dev=1]model.vision.linear_proj.dense_4h_to_h.weight:  25%|██▌       | 1/4 [00:00<00:00,  3.14w/s, dev=1]model.vision.linear_proj.dense_h_to_4h.weight:  25%|██▌       | 1/4 [00:00<00:00,  3.14w/s, dev=1]model.vision.linear_proj.gate_proj.weight:  50%|█████     | 2/4 [00:00<00:00,  5.66w/s, dev=1]    lm_head.weight:  75%|███████▌  | 3/4 [00:00<00:00,  7.35w/s, dev=1]                           lm_head.weight: 100%|██████████| 4/4 [00:00<00:00,  4.92w/s, dev=1]                                                                   Data successfully written to renaissance_evaluation_sample_cogvlm_data.js

###############################################################################
Hábrók Cluster
Job 11262793 for user s1889338
Finished at: Mon Jul  8 01:22:57 CEST 2024

Job details:
============

Job ID                         : 11262793
Name                           : autocap
User                           : s1889338
Partition                      : gpulong
Nodes                          : a100gpu4
Number of Nodes                : 1
Cores                          : 16
Number of Tasks                : 1
State                          : RUNNING  
Submit                         : 2024-07-08T00:36:32
Start                          : 2024-07-08T00:37:16
End                            : --
Reserved walltime              : 2-23:59:00
Used walltime                  :   00:45:41
Used CPU time                  : -- 
% User (Computation)           : --
% System (I/O)                 : --
Total memory reserved          : 50G
Maximum memory used            : --
Requested GPUs                 : a100=2
Allocated GPUs                 : a100=2
Max GPU utilization            : --
Max GPU memory used            : --

Acknowledgements:
=================

Please see this page for information about acknowledging Hábrók in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
